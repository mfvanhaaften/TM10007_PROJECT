{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the following sections:\n",
    "\n",
    "1. Installing and importing functions and packages\n",
    "\n",
    "2. Loading and splitting data\n",
    "3. Preprocessing before crossvalidation\n",
    "\n",
    "   3.1 Overview of NaN's in the dataset\n",
    "\n",
    "   3.2 Feature removal based on the number of NaN's\n",
    "\n",
    "   3.3 Patient removal based on the number of NaN's\n",
    "   \n",
    "   3.4 Evaluation of data distribution and outliers\n",
    "\n",
    "4. Function definitions\n",
    "\n",
    "    4.1 Imputation\n",
    "    \n",
    "    4.2 Scaling\n",
    "\n",
    "    4.3 Feature selection/dimensionality reduction\n",
    "\n",
    "    4.4 Hyperparameter optimization feature selection method\n",
    "\n",
    "    4.5 Randomized grid searches\n",
    "\n",
    "    4.6 Performance metrics\n",
    "\n",
    "    4.7 Learning curves\n",
    "\n",
    "5. Evaluation of feature selection methods\n",
    "\n",
    "6. Outer and inner crossvalidation\n",
    "\n",
    "7. Performance of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing and importing functions and packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "# !pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "# !pip install missingpy\n",
    "# !pip install flake8 pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import shapiro, uniform\n",
    "from sklearn.model_selection import (\n",
    "                                    StratifiedKFold, StratifiedShuffleSplit,\n",
    "                                    RandomizedSearchCV, learning_curve)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import (\n",
    "                                    RFECV, SelectKBest, mutual_info_classif, \n",
    "                                    SelectFromModel)\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from missingpy import KNNImputer\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle_on\n",
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and splitting data "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA = load_data()\n",
    "\n",
    "# Splitting data into feature values and patient labels\n",
    "FEATURES = DATA.drop(columns=['label'])\n",
    "LABELS = DATA['label']\n",
    "\n",
    "GBM = FEATURES.loc[LABELS == 'GBM']\n",
    "LGG = FEATURES.loc[LABELS == 'LGG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing before crossvalidation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Overview of NaN's in the dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "\n",
    "# Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_ROW_TOTAL = FEATURES.isnull().sum(axis=1)\n",
    "# Number of NaN's per feature for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = FEATURES.isnull().sum(axis=0)\n",
    "\n",
    "# Number of NaN's per feature for GBM patients\n",
    "GBM_NO_NAN_COL = GBM.isnull().sum(axis=0)\n",
    "# Number of NaN's per feature for LGG patients\n",
    "LGG_NO_NAN_COL = LGG.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Feature removal based on the number of NaN's. \n",
    "\n",
    "Threshold = the maximum number of NaN's in a column, above which a feature is removed from the dataset."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "482 of 724 features are left in dataset\n"
    }
   ],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 30\n",
    "PERC_MISSING_LGG = 30\n",
    "\n",
    "# Define threshold based on number of NaN's for discarding features\n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be removed\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "DATA_FEAT_SEL = FEATURES.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL.columns)} of {len(FEATURES.columns)} features are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Patient removal based on the number of NaN's. \n",
    "\n",
    "Threshold = the maximum number of NaN's in a row, above which the patient is removed from the dataset."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The following sample(s) is/are removed from dataset:\nTCGA-HT-7686\n166 of 167 samples are left in dataset\n"
    }
   ],
   "source": [
    "# Define threshold of number of NaN's above which a patient is removed\n",
    "PERC_MISSING_SAMPLE = 30\n",
    "THRESHOLD_SAMPLE = floor((PERC_MISSING_SAMPLE/100) * len(DATA_FEAT_SEL.columns))\n",
    "\n",
    "# Number of NaN's per patient after feature removal\n",
    "NO_NAN_ROW_FEAT_SEL = DATA_FEAT_SEL.isnull().sum(axis=1)\n",
    "\n",
    "# Initialisation\n",
    "SAMPLES_REMOVED = []\n",
    "LABELS_SEL = LABELS\n",
    "\n",
    "# Looping over the dataset after feature removal to remove patients with a number \n",
    "# of NaN's above the threshold\n",
    "print('The following sample(s) is/are removed from dataset:')\n",
    "for sample in NO_NAN_ROW_FEAT_SEL[NO_NAN_ROW_FEAT_SEL > THRESHOLD_SAMPLE].index[:]:\n",
    "    if sample:\n",
    "        print(sample)\n",
    "        SAMPLES_REMOVED.append(sample)\n",
    "        DATA_FEAT_SEL = DATA_FEAT_SEL.drop(index=sample)\n",
    "        LABELS_SEL = LABELS_SEL.drop(index=sample)\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL)} of {len(FEATURES)} samples are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Evaluation of data distribution and outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "In the GBM class, 435 features are not normally distributed\nIn the LGG class, 384 features are not normally distributed\n"
    }
   ],
   "source": [
    "# Evaluate data distribution using Shapiro test\n",
    "\n",
    "# Impute GBM and LGG patients separately\n",
    "IMPUTER_GBM = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "IMPUTER_LGG = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "\n",
    "X_GBM = DATA_FEAT_SEL[LABELS_SEL == 'GBM']\n",
    "X_IMP_GBM = IMPUTER_GBM.fit_transform(X_GBM)\n",
    "\n",
    "X_LGG = DATA_FEAT_SEL[LABELS_SEL == 'LGG']\n",
    "X_IMP_LGG = IMPUTER_LGG.fit_transform(X_LGG)\n",
    "\n",
    "# Evaluate distributions of features for GBM patients\n",
    "NO_NON_NORMAL_GBM = 0\n",
    "FEAT_NON_NORM_GBM = list()\n",
    "\n",
    "for index, feature in enumerate(X_IMP_GBM.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value < 0.05:\n",
    "        # Number of non normally distributed features\n",
    "        NO_NON_NORMAL_GBM += 1          \n",
    "        FEAT_NON_NORM_GBM.append(index)\n",
    "\n",
    "print(f'In the GBM class, {NO_NON_NORMAL_GBM} features are not normally distributed')\n",
    "\n",
    "# Evaluate distributions of features for LGG patients\n",
    "NO_NON_NORMAL_LGG = 0\n",
    "FEAT_NON_NORM_LGG = list()\n",
    "for index, feature in enumerate(X_IMP_LGG.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value < 0.05:\n",
    "        # Number of non normally distributed features\n",
    "        NO_NON_NORMAL_LGG += 1          \n",
    "        FEAT_NON_NORM_LGG.append(index)\n",
    "\n",
    "print(f'In the LGG class, {NO_NON_NORMAL_LGG} features are not normally distributed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "In the GBM class, 7 patients are considered to be outliers\nIn the LGG class, 4 patients are considered to be outliers.\nFor the complete dataset, this means that 6.626506024096386% is an outlier\n"
    }
   ],
   "source": [
    "# Evaluate number of outliers per patient group (LGG and GBM), \n",
    "# depending on the Interquartile Range (IQR)\n",
    "\n",
    "# Evaluate per GBM patient each feature\n",
    "NO_OUTLIERS_GBM = 0\n",
    "\n",
    "# Loop over patients\n",
    "for patient in X_IMP_GBM:\n",
    "    feat_out = 0\n",
    "    # Loop over features\n",
    "    for index, feature in enumerate(patient):\n",
    "        # Determine quartiles and interquartile range (IQR)\n",
    "        q25, q75 = np.percentile(X_IMP_GBM[:,index], 25), np.percentile(X_IMP_GBM[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        # Define cut-off for outlier evaluation and lower and upper bounds\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        # Determine whether patient has an exceptional feature value\n",
    "        outlier = ((feature > upper) | (feature < lower))\n",
    "        # Count number of features for which patient has exceptional feature value\n",
    "        feat_out += outlier\n",
    "    # Classify patient as outlier when he has exceptional values for > 70 features\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS_GBM += 1\n",
    "\n",
    "print(f'In the GBM class, {NO_OUTLIERS_GBM} patients are considered to be outliers')\n",
    "\n",
    "# Evaluate per LGG patient each feature\n",
    "NO_OUTLIERS_LGG = 0\n",
    "\n",
    "for patient in X_IMP_LGG:\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):\n",
    "        q25, q75 = np.percentile(X_IMP_LGG[:,index], 25), np.percentile(X_IMP_LGG[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        outlier = ((feature>upper) | (feature<lower))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS_LGG += 1\n",
    "\n",
    "print(f'In the LGG class, {NO_OUTLIERS_LGG} patients are considered to be outliers.')\n",
    "print(f\"For the complete dataset, this means that {(NO_OUTLIERS_LGG + NO_OUTLIERS_GBM)/(len(DATA_FEAT_SEL)) * 100}% is an outlier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function definitions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute_train_test_set(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Fit k-nearest neighbor imputer on train set and impute train and test set using this fitted imputer.\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "\n",
    "    Output:\n",
    "    X_train_imp: array-like, shape (n_samples, n_features)\n",
    "                Imputed train data.\n",
    "\n",
    "    X_test_imp: array-like, shape (n_samples, n_features)\n",
    "                Imputed test data.\n",
    "    \"\"\"\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "    imputer.fit(X_train)\n",
    "    X_train_imp = imputer.transform(X_train)\n",
    "    X_test_imp = imputer.transform(X_test)\n",
    "    return X_train_imp, X_test_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_train_test_set(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Fit MinMax scaler on train set and scale train and test set using this fitted scaler.\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "\n",
    "    Output:\n",
    "    X_train_scal: array-like, shape (n_samples, n_features)\n",
    "                Scaled train data.\n",
    "\n",
    "    X_test_scal: array-like, shape (n_samples, n_features)\n",
    "                Scaled test data.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    return X_train_scal, X_test_scal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Feature selection/dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_univariate(X_train, y_train, X_test, k_value):\n",
    "    \"\"\"\n",
    "    Univariate feature selection using the Mutual Information Criterion.\n",
    "    Fit on training set and transform training and test set.\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "                Target relative to X_train for classification.\n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "\n",
    "    Output:\n",
    "    X_train_sel: array-like, shape (n_samples, n_features_selected)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features_selected is the number of selected features.\n",
    "    X_test_sel: array-like, shape (n_samples, n_features_selected)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features_selected is the number of selected features.\n",
    "    selection_method.get_support: array-like\n",
    "                Indices of the feature columns dat were selected\n",
    "    \"\"\"\n",
    "    selection_method = SelectKBest(mutual_info_classif, k=k_value).fit(X_train, y_train)\n",
    "    X_train_sel = selection_method.transform(X_train)\n",
    "    X_test_sel = selection_method.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, selection_method.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_l1(X_train, y_train, X_test, threshold_value):\n",
    "    \"\"\"\n",
    "    L1-based feature selection. Fit on training set and transform training and test set.\n",
    "\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "                Target relative to X_train for classification.\n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    threshold_value: string or float\n",
    "                The threshold value to use for feature selection.\n",
    "\n",
    "    Output:\n",
    "    X_train_sel: array-like, shape (n_samples, n_features_selected)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features_selected is the number of selected features.\n",
    "    X_test_sel: array-like, shape (n_samples, n_features_selected)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features_selected is the number of selected features.\n",
    "    \"\"\"\n",
    "    lsvc = LinearSVC(penalty=\"l1\", dual=False, max_iter=10000).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True, threshold=threshold_value)\n",
    "    X_train_sel = model.transform(X_train)\n",
    "    X_test_sel = model.transform(X_test)\n",
    "    print(f' \\n Number of features selected by L1 feature selection: {len(model.get_support(indices=True))}')\n",
    "    print(f' \\n The following column indices of features were selected by L1 feature selection:'\\\n",
    "                f'\\n {model.get_support(indices=True)}')\n",
    "    return X_train_sel, X_test_sel, model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_rfecv(X_train, y_train, scoring):\n",
    "    \"\"\"\n",
    "    Recursive feature elimination using crossvalidation (rfecv).\n",
    "    Fit on training set and return column indices of selected features.\n",
    "\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "                Target relative to X_train for classification.\n",
    "    scoring: string\n",
    "                Scoring metric to be used.\n",
    "\n",
    "    Output:\n",
    "    rfecv.get_support: array-like\n",
    "                Column indices of selected features.\n",
    "    \"\"\"\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    optimal_number_features = list()\n",
    "\n",
    "    # classifications\n",
    "    rfecv = RFECV(\n",
    "        estimator=svc, step=1,\n",
    "        cv=StratifiedKFold(4),\n",
    "        scoring=scoring)\n",
    "    rfecv.fit(X_train, y_train)\n",
    "\n",
    "    optimal_number_features.append(rfecv.n_features_)\n",
    "    print(\"\\n Optimal number of features according to rfecv: %d\" % rfecv.n_features_)\n",
    "    print(f' \\n The following column indices of features were selected by RFECV: \\n {rfecv.get_support(indices=True)}')\n",
    "    return rfecv.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(X_train, X_test, components):\n",
    "    \"\"\"\n",
    "    Conduct PCA-analysis. Fit on train set and transform train and test set.\n",
    "\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "            Test vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "    component: int\n",
    "            The number of components to be used.\n",
    "\n",
    "    Output:\n",
    "    X_train_pca: array-like, shape (n_samples, n_components)\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_components is the number of components.\n",
    "    X_test_pca: array-like, shape (n_samples, n_components)\n",
    "            Test vector, where n_samples is the number of samples and\n",
    "            n_components is the number of components.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Hyperparameter optimization feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def select_hyperparameter_feature_selection(X_train, y_train, hyperparameter_options):\n",
    "    \"\"\"\n",
    "    Determines optimal value for a hyperparameter, e.g. the number of features\n",
    "    to be selected (k), of the univariate feature selection method. The train\n",
    "    set that is provided as input is dividied into train and test sets using K-Fold\n",
    "    crossvalidation. The choice for the best hyperparameter value is based on the\n",
    "    performance of a KNN-classifier trained with the features selected by the univariate\n",
    "    feature selection. The hyperparameter value that results in the highest mean Area\n",
    "    under the Receiver Operator Curve (AUC) score across the 5 folds, is selected as optimal value.\n",
    "\n",
    "    Input:\n",
    "    X-train: X_train : array-like, shape (n_samples, n_features)\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "            Target relative to X_train for classification.\n",
    "\n",
    "    hyperparameter_options: list of settings for the hyperparameter to be evaluated.\n",
    "\n",
    "    Output:\n",
    "    param_optimal: float or int, based on the variable types in hyperparameter_options\n",
    "                The value for the hyperparameter that results in the highest mean AUC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialisation\n",
    "    clf_inner = KNeighborsClassifier(n_neighbors=15, weights=\"distance\")\n",
    "    skf_inner = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    performance_param_inner = pd.DataFrame()\n",
    "\n",
    "    # Inner crossvalidation\n",
    "    for train_index_inner, validation_index_inner in skf_inner.split(X_train, y_train):\n",
    "\n",
    "        # Train and validation split\n",
    "        X_train_inner, X_val_inner = np.array(X_train)[train_index_inner], np.array(X_train)[validation_index_inner]\n",
    "        y_train_inner, y_val_inner = np.array(y_train)[train_index_inner], np.array(y_train)[validation_index_inner]\n",
    "\n",
    "        # Initialisation\n",
    "        acc_inner = dict()\n",
    "        bal_acc_inner = dict()\n",
    "        roc_auc_score_inner = dict()\n",
    "\n",
    "        # Loop over different values for hyperparameter\n",
    "        for param in hyperparameter_options:\n",
    "            X_train_sel_inner, X_val_sel_inner, selected_indices_inner = \\\n",
    "                                                                select_features_univariate(X_train_inner, y_train_inner,                                                                                                         X_val_inner, param)       \n",
    "            acc_inner[str(param)], bal_acc_inner[str(param)], roc_auc_score_inner[str(param)] = \\\n",
    "                                                                get_performance_classifier(\n",
    "                                                                                          clf_inner, X_train_sel_inner, \n",
    "                                                                                          y_train_inner, X_val_sel_inner, \n",
    "                                                                                          y_val_inner)\n",
    "\n",
    "        performance_param_inner = performance_param_inner.append(roc_auc_score_inner, ignore_index=True)\n",
    "\n",
    "    print(f'The performances of different hyperparameter-values across the five folds is:'\\\n",
    "          f'\\n{performance_param_inner}')\n",
    "\n",
    "    # Compute mean performance and choose optimal value for hyperparameter\n",
    "    mean_performance_param_inner = performance_param_inner.mean()\n",
    "    param_optimal = int(mean_performance_param_inner.idxmax(axis=1))\n",
    "    return param_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 Randomized grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_randomized_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform a Randomized Grid Search on the training set to find\n",
    "    the optimal hyperparameters for the RF classifier.\n",
    "    Hyperparameters that are tuned are: n_estimators, max_features,\n",
    "    min_samples_split, max_depth and min_samples_leaf.\n",
    "\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "        Target relative to X_train for classification.\n",
    "\n",
    "    Output:\n",
    "    rf_classifier: estimator\n",
    "        Estimator that was chosen by the search, i.e. estimator\n",
    "        which gave highest score on the left out data.\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators': [32, 64, 128],\n",
    "        'max_features': ['sqrt', 'log2', 0.10, 0.25, 0.50],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'max_depth': [1, 6, 15, 28],\n",
    "        'min_samples_leaf': [0.05, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    grid = RandomizedSearchCV(RandomForestClassifier(), parameters, refit=True, verbose=0, n_iter=20)\n",
    "    grid.fit(X_train, y_train)\n",
    "    rf_classifier = grid.best_estimator_\n",
    "    return rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_randomized_search(X_train, y_train):\n",
    "    \"\"\"Perform a Randomized Grid Search on the training set to find\n",
    "    the optimal hyperparameters for the KNN-classifier. \n",
    "    Hyperparameters that are tuned are: n_neighbors and weights.\n",
    "\n",
    "    Input:\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples\n",
    "        and n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "        Target relative to X_train for classification.\n",
    "\n",
    "    Output:\n",
    "    knn_classifier: estimator\n",
    "        Estimator that was chosen by the search, i.e. estimator\n",
    "        which gave highest score on the left out data.\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = {'n_neighbors': list(range(15, 20)),\n",
    "                  'weights': [\"uniform\", \"distance\"]}\n",
    "\n",
    "    grid = RandomizedSearchCV(KNeighborsClassifier(), parameters, refit=True, verbose=0, n_iter=10)\n",
    "    grid.fit(X_train, y_train)\n",
    "    knn_classifier = grid.best_estimator_\n",
    "    return knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_randomized_search(X_train, y_train):\n",
    "    \"\"\"Perform a Randomized Search on the training set to find \n",
    "    the optimal hyperparameters for the SVM classifier. \n",
    "    Hyperparameters that are tuned are: kernel, C, gamma, degree \n",
    "    and coef0.\n",
    "\n",
    "    Input: \n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples \n",
    "        and n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "        \n",
    "    Output: \n",
    "    svm_classifier: estimator\n",
    "        Estimator that was chosen by the search, i.e. estimator \n",
    "        which gave highest score on the left out data. \n",
    "    \"\"\"\n",
    "\n",
    "    parameters = {'kernel': ['linear', 'rbf', 'poly'],\n",
    "                  'C': uniform(loc=0.01, scale=100),\n",
    "                  'gamma': ['scale', 'auto'],\n",
    "                  'degree': [1, 2, 3, 4, 5],\n",
    "                  'coef0': uniform(loc=0.01, scale=19.99)}\n",
    "\n",
    "    grid = RandomizedSearchCV(SVC(probability=True), parameters, refit=True, verbose=0, n_iter=20)\n",
    "    grid.fit(X_train, y_train)\n",
    "    svm_classifier = grid.best_estimator_\n",
    "    return svm_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_classifier(classifier, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train classifier and obtain its performance on an independent test set.\n",
    "\n",
    "    Input:\n",
    "    classifier: classifier object that can be fitted to training data.\n",
    "\n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "                Training vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    y_train: array-like, shape (n_samples)\n",
    "             Target relative to X_train for classification.\n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "                Test vector, where n_samples is the number of samples and\n",
    "                n_features is the number of features.\n",
    "    y_test: array-like, shape (n_samples)\n",
    "                Target relative to X_test for classification.\n",
    "\n",
    "    Output:\n",
    "    accuracy: float\n",
    "                Accuracy of classifier.\n",
    "\n",
    "    balanced_acc: float\n",
    "                Balanced accuracy of classifier.\n",
    "\n",
    "    roc_auc: float64\n",
    "                Area under the receiver operator curve.\n",
    "    \"\"\"\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    prediction = classifier.predict(X_test)\n",
    "\n",
    "    # Obtain probabilities of prediction\n",
    "    order_classes = list(classifier.classes_)\n",
    "    positive_class = order_classes.index('LGG')\n",
    "    probability = classifier.predict_proba(X_test)[:, positive_class]\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "    balanced_acc = metrics.balanced_accuracy_score(y_test, prediction)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, probability)\n",
    "\n",
    "    return accuracy, balanced_acc, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.7 Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Input:\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "    Output:\n",
    "    Plot of learning curve\n",
    "    \"\"\"\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                      train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                      color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                      test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                      color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "              label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "              label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n Fold 1 of evaluation of feature selection methods\n\n The following column indices of features were selected by univariate feature selection: \n [  0   6   7   8   9  10  12  13  16  28 113 131 197 236 393 394 414 470\n 471 473]\n\n The following column indices of features were selected by univariate feature selection: \n [  0   6   7   8   9  10  12  13  16  28 113 131 161 197 234 236 242 280\n 283 290 292 310 384 387 392 393 394 409 410 413 414 466 470 471 473]\n\n The following column indices of features were selected by univariate feature selection: \n [  0   2   6   7   8   9  10  12  13  16  25  28  98 111 113 131 161 197\n 200 230 234 236 237 242 251 260 280 283 290 292 310 317 384 387 392 393\n 394 409 410 413 414 419 422 424 432 466 468 470 471 473]\n\n Optimal number of features according to rfecv: 20\n \n The following column indices of features were selected by RFECV: \n [  8   9  10  11  12  17  28  35  57  58 121 179 197 200 337 354 401 430\n 455 481]\n\n Optimal number of features according to rfecv: 20\n \n The following column indices of features were selected by RFECV: \n [  8   9  10  11  12  17  28  35  57  58 121 179 197 200 337 354 401 430\n 455 481]\n\n Optimal number of features according to rfecv: 20\n \n The following column indices of features were selected by RFECV: \n [  8   9  10  11  12  17  28  35  57  58 121 179 197 200 337 354 401 430\n 455 481]\n \n Number of features selected by L1 feature selection: 42\n \n The following column indices of features were selected by L1 feature selection:\n [  9  11  17  28  33  35  36  44  51  54  57  62  66 110 113 121 122 131\n 145 150 179 200 248 250 314 337 354 367 377 379 401 430 455 459 467 474\n 475 476 477 478 480 481]\n \n Number of features selected by L1 feature selection: 42\n \n The following column indices of features were selected by L1 feature selection:\n [  9  11  17  28  33  35  36  44  51  54  57  62  66 110 113 121 122 131\n 145 150 179 200 248 250 314 337 354 367 377 379 401 430 455 459 467 474\n 475 476 477 478 480 481]\n \n Number of features selected by L1 feature selection: 41\n \n The following column indices of features were selected by L1 feature selection:\n [  9  11  17  28  33  35  36  44  51  54  57  62  66 110 113 121 122 131\n 150 179 200 248 250 314 337 354 367 377 379 401 430 455 459 467 474 475\n 476 477 478 480 481]\n\n Fold 2 of evaluation of feature selection methods\n\n The following column indices of features were selected by univariate feature selection: \n [  0   6   7   9  10  12  13  16  98 131 197 236 237 252 260 314 392 466\n 471 475]\n\n The following column indices of features were selected by univariate feature selection: \n [  0   1   6   7   8   9  10  12  13  16  98 131 161 182 197 200 206 234\n 236 237 252 260 290 292 314 355 384 387 392 394 432 461 466 471 475]\n\n The following column indices of features were selected by univariate feature selection: \n [  0   1   6   7   8   9  10  12  13  16  25  28  98 131 161 179 182 197\n 200 206 230 234 236 237 247 252 260 280 290 292 314 331 355 384 387 392\n 394 417 419 422 432 434 435 461 466 467 468 471 473 475]\n\n Optimal number of features according to rfecv: 20\n \n The following column indices of features were selected by RFECV: \n [  5   8   9  10  12  17  21  24  51  57  93 111 118 237 252 276 337 401\n 477 481]\n\n Optimal number of features according to rfecv: 12\n \n The following column indices of features were selected by RFECV: \n [  5   8   9  10  12  24  57 237 252 337 401 477]\n\n Optimal number of features according to rfecv: 1\n \n The following column indices of features were selected by RFECV: \n [12]\n \n Number of features selected by L1 feature selection: 38\n \n The following column indices of features were selected by L1 feature selection:\n [  5   9  10  11  12  17  21  24  33  35  36  42  51  54  57  93  95 110\n 115 118 119 121 151 157 186 202 220 237 278 337 401 408 429 455 476 477\n 478 481]\n \n Number of features selected by L1 feature selection: 37\n \n The following column indices of features were selected by L1 feature selection:\n [  5   9  10  11  12  17  21  24  33  35  36  42  51  54  57  93  95 110\n 115 118 119 121 151 157 202 220 237 278 337 401 408 429 455 476 477 478\n 481]\n \n Number of features selected by L1 feature selection: 36\n \n The following column indices of features were selected by L1 feature selection:\n [  5   9  10  11  12  17  21  24  33  35  36  42  51  57  93  95 110 115\n 118 119 121 151 157 202 220 237 278 337 401 408 429 455 476 477 478 481]\n\n Fold 3 of evaluation of feature selection methods\n\n The following column indices of features were selected by univariate feature selection: \n [  0   6   7   8   9  10  12  13  16 131 164 197 218 394 409 461 466 471\n 473 475]\n\n The following column indices of features were selected by univariate feature selection: \n [  0   1   6   7   8   9  10  12  13  16  17  28 112 131 161 164 182 197\n 200 218 280 383 387 394 409 414 419 432 461 466 468 470 471 473 475]\n\n The following column indices of features were selected by univariate feature selection: \n [  0   1   6   7   8   9  10  12  13  16  17  25  28  58  98 112 113 131\n 161 164 179 182 197 200 218 280 283 288 305 331 383 384 387 394 409 414\n 415 417 419 422 432 456 461 463 466 468 470 471 473 475]\n\n Optimal number of features according to rfecv: 79\n \n The following column indices of features were selected by RFECV: \n [  0   1   8   9  10  12  17  19  23  24  35  47  51  57  58  60  74  75\n  77  86  87  88  89  90  93  95  96 102 110 118 120 121 124 129 131 132\n 148 161 179 182 189 197 200 204 205 206 209 238 250 264 265 278 296 315\n 325 327 337 338 339 349 351 353 354 367 377 379 397 400 401 410 413 415\n 427 429 431 441 443 455 481]\n\n Optimal number of features according to rfecv: 6\n \n The following column indices of features were selected by RFECV: \n [  9  10  17  57 337 481]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-371f1c03fb6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlist_rfecv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_rfecv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_features_rfecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mX_train_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_scal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mX_test_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_scal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-979eb20b8024>\u001b[0m in \u001b[0;36mselect_features_rfecv\u001b[0;34m(X_train, y_train, scoring)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         scoring=scoring)\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0moptimal_number_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    531\u001b[0m         scores = parallel(\n\u001b[1;32m    532\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    531\u001b[0m         scores = parallel(\n\u001b[1;32m    532\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     return rfe._fit(\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;31m# that have not been eliminated yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0msupport_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mranking_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(estimator, features)\u001b[0m\n\u001b[1;32m     32\u001b[0m     return rfe._fit(\n\u001b[1;32m     33\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    167\u001b[0m                           stacklevel=2)\n\u001b[1;32m    168\u001b[0m         return self._score(partial(_cached_call, None), estimator, X, y_true,\n\u001b[0;32m--> 169\u001b[0;31m                            sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 212\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mbalanced_accuracy_score\u001b[0;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \"\"\"\n\u001b[0;32m-> 1855\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0mper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -------------------------- Cross Validation Feature Selection---------------------------------------------------\n",
    "skf_eval_sel = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "DICT_UNI = {'20': [], '35': [], '50': []}\n",
    "DICT_RFECV = {'roc_auc': [], 'accuracy': [], 'balanced_accuracy': []}\n",
    "DICT_L1 = {'1e-05': [], '0.001': [], '0.01': []}\n",
    "DICT_PCA = {'10': [], '20': [], '30': []}\n",
    "FOLD_SEL = 0\n",
    "\n",
    "for train_index, test_index in skf_eval_sel.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    FOLD_SEL += 1\n",
    "    print(f'\\n Fold {FOLD_SEL} of evaluation of feature selection methods')\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "    X_train_imp, X_test_imp = knn_impute_train_test_set(X_train, X_test)\n",
    "    X_train_scal, X_test_scal = scale_train_test_set(X_train_imp, X_test_imp)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "\n",
    "    # Univariate feature selection\n",
    "    list_uni = [20, 35, 50]\n",
    "    for number in list_uni:\n",
    "        X_train_sel, X_test_sel, selected_indices = select_features_univariate(\n",
    "                                                                              X_train_scal, y_train, \n",
    "                                                                              X_test_scal, number)\n",
    "        acc_uni, bal_acc_uni, roc_uni = get_performance_classifier(\n",
    "                                                                  clf, X_train_sel, y_train, \n",
    "                                                                  X_test_sel, y_test)\n",
    "        DICT_UNI[str(number)].append(roc_uni)\n",
    "        print(f'\\n The following column indices of features were selected by '\\\n",
    "              f'univariate feature selection: \\n {selected_indices}')\n",
    "\n",
    "    # RFECV feature selection\n",
    "    list_rfecv = ['roc_auc', 'accuracy', 'balanced_accuracy']\n",
    "    for scoring in list_rfecv:\n",
    "        selected_features = select_features_rfecv(X_train_scal, y_train, scoring)\n",
    "        X_train_sel = X_train_scal[:, selected_features]\n",
    "        X_test_sel = X_test_scal[:, selected_features]\n",
    "        acc_rfecv, bal_acc_rfecv, roc_rfecv = get_performance_classifier(\n",
    "                                                                        clf, X_train_sel, y_train,                                                                                                            X_test_sel, y_test)\n",
    "        DICT_RFECV[scoring].append(roc_rfecv)\n",
    "\n",
    "    # L1 feature selection\n",
    "    list_L1 = [0.00001, 0.001, 0.01]\n",
    "    for value in list_L1:\n",
    "        X_train_sel, X_test_sel, selected_indices = select_features_l1(\n",
    "                                                                      X_train_scal, y_train, \n",
    "                                                                      X_test_scal, value)\n",
    "        acc_L1, bal_acc_L1, roc_L1 = get_performance_classifier(\n",
    "                                                               clf, X_train_sel, \n",
    "                                                               y_train, X_test_sel, y_test)\n",
    "        DICT_L1[str(value)].append(roc_L1)\n",
    "\n",
    "    # PCA feature selection\n",
    "    list_pca = [10, 20, 30]\n",
    "    for component in list_pca:\n",
    "        X_train_sel, X_test_sel = pca_analysis(X_train_scal, X_test_scal, component)\n",
    "        acc_pca, bal_acc_pca, roc_pca = get_performance_classifier(\n",
    "                                                                  clf, X_train_sel, \n",
    "                                                                  y_train, X_test_sel, y_test)\n",
    "        DICT_PCA[str(component)].append(roc_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean ROC-AUC of univariate, 20 best: 0.9291107041107041\nMean ROC-AUC of univariate, 35 best: 0.9284086284086284\nMean ROC-AUC of univariate, 50 best: 0.9307081807081806\nMean ROC-AUC of RFECV, roc_auc scoring: 0.9087810337810338\nMean ROC-AUC of RFECV, accuracy scoring: 0.9001017501017502\nMean ROC-AUC of RFECV, balanced_accuracy scoring: 0.8635531135531136\nMean ROC-AUC of L1, threshold of 1e-05: 0.8884310134310134\nMean ROC-AUC of L1, threshold of 0.001: 0.881486568986569\nMean ROC-AUC of L1, threshold of 0.01: 0.8843101343101343\nMean ROC-AUC of PCA, 10 components: 0.8962148962148961\nMean ROC-AUC of PCA, 20 components: 0.9151404151404151\nMean ROC-AUC of PCA, 30 components: 0.9227716727716727\n"
    }
   ],
   "source": [
    "# Evaluate the different feature selection methods by comparing ROC\n",
    "for key, values in DICT_UNI.items():\n",
    "    mean_values = np.mean(values)\n",
    "    print(f'Mean ROC-AUC of univariate, {key} best: {mean_values}')\n",
    "for key, values in DICT_RFECV.items():\n",
    "    mean_values = np.mean(values)\n",
    "    print(f'Mean ROC-AUC of RFECV, {key} scoring: {mean_values}')\n",
    "for key, values in DICT_L1.items():\n",
    "    mean_values = np.mean(values)\n",
    "    print(f'Mean ROC-AUC of L1, threshold of {key}: {mean_values}')\n",
    "for key, values in DICT_PCA.items():\n",
    "    mean_values = np.mean(values)\n",
    "    print(f'Mean ROC-AUC of PCA, {key} components: {mean_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outer and inner crossvalidation "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n \n Run 1 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is:\n         20        30        40        50\n0  1.000000  1.000000  0.988235  0.994118\n1  0.872159  0.886364  0.869318  0.852273\n2  0.918750  0.918750  0.921875  0.918750\n3  0.900000  0.943750  0.937500  0.937500\n4  0.934375  0.931250  0.956250  0.918750\nThe optimal k value for fold 1 is: 30\n\n The following column indices of features were selected by univariate feature selection: \n [  0   6   7   8   9  10  12  13  16  28 113 131 161 197 234 236 242 280\n 283 290 292 384 387 393 394 409 414 470 471 473]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e0bed89e0420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0msvm_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_randomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mrf_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_randomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mknn_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_randomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-9b4f73d0c5d7>\u001b[0m in \u001b[0;36mrf_randomized_search\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mrf_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrf_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf_outer = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Initialization\n",
    "FEATURES_SELECTED_TOTAL = list()\n",
    "FOLD = 0\n",
    "\n",
    "# Create dataframes\n",
    "ACCURACY = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "ACCURACY_BALANCED = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "AUC = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "\n",
    "for train_index, test_index in skf_outer.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    FOLD += 1\n",
    "    print(f'\\n \\n Run {FOLD} of outer crossvalidation')\n",
    "\n",
    "    # Split data into train and test set for outer crossvalidation\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "\n",
    "    # ---------------------------------- IMPUTATION -----------------------------------\n",
    "\n",
    "    X_train_imp, X_test_imp = knn_impute_train_test_set(X_train, X_test)\n",
    "\n",
    "    # ------------------------------------ SCALING ----------------------------------------\n",
    "    X_train_scal, X_test_scal = scale_train_test_set(X_train_imp, X_test_imp)\n",
    "\n",
    "    # ------------------------------------ FEATURE SELECTION -------------------------------\n",
    "\n",
    "    # Determining optimal number of features k\n",
    "    k_options = [20, 30, 40, 50]\n",
    "    k_optimal = select_hyperparameter_feature_selection(X_train_scal, y_train, k_options)\n",
    "    print(f'The optimal k value for fold {FOLD} is: {k_optimal}')\n",
    "\n",
    "    # Univariate feature selection\n",
    "    X_train_sel, X_test_sel, selected_indices = select_features_univariate(\n",
    "                                                                          X_train_scal, y_train, \n",
    "                                                                          X_test_scal, k_value=k_optimal)\n",
    "\n",
    "    print(f'\\n The following column indices of features were selected by univariate feature selection: \\n {selected_indices}')\n",
    "    # Determine names of features that were selected\n",
    "    features_selected = list()\n",
    "    for index in selected_indices:\n",
    "        features_selected.append(DATA_FEAT_SEL.columns[index])\n",
    "    FEATURES_SELECTED_TOTAL.append(features_selected)\n",
    "\n",
    "    # -------------- INNER CROSSVALIDATION FOR DETERMINATION OF HYPERPARAMETERS OF CLASSIFIERS ----------------------------\n",
    "    svm_classifier = svm_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    rf_classifier = rf_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    knn_classifier = knn_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    clfs = [svm_classifier, rf_classifier, knn_classifier]\n",
    "    clfs_names = ['SVM', 'RF', 'KNN']\n",
    "\n",
    "    # ---------------- TRAIN AND TEST CLASSIFIERS (OUTER CROSSVALIDATION) ------------------------------------------------\n",
    "    # Initialisation\n",
    "    # Accuracy\n",
    "    acc_dict = dict()\n",
    "    accuracy_total = list()\n",
    "\n",
    "    # Balanced accuracy\n",
    "    bal_acc_dict = dict()\n",
    "    bal_acc_total = list()\n",
    "\n",
    "    # AUC \n",
    "    roc_auc_score_dict = dict()\n",
    "    roc_auc_score_total = list()\n",
    "\n",
    "    # Determine performance\n",
    "    for clf, name in zip(clfs, clfs_names):\n",
    "        acc_dict[name], bal_acc_dict[name], roc_auc_score_dict[name] = get_performance_classifier(\n",
    "                                                                                                 clf, X_train_sel, y_train,                                                                                                            X_test_sel, y_test)\n",
    "\n",
    "    accuracy_total.append(acc_dict)\n",
    "    bal_acc_total.append(bal_acc_dict)\n",
    "    roc_auc_score_total.append(roc_auc_score_dict)\n",
    "\n",
    "    ACCURACY = ACCURACY.append(acc_dict, ignore_index=True)\n",
    "    ACCURACY_BALANCED = ACCURACY_BALANCED.append(bal_acc_dict, ignore_index=True)\n",
    "    AUC = AUC.append(roc_auc_score_dict, ignore_index=True)\n",
    "\n",
    "    print(f'Regular accuracy: \\n {acc_dict}')\n",
    "    print(f'Balanced accuracy: \\n {bal_acc_dict}')\n",
    "    print(f'RoOC-AUCscore: \\n {roc_auc_score_dict}')\n",
    "\n",
    "    # -------------------- LEARNING CURVES --------------------------------------------------\n",
    "    # Initialisation\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    num = 0\n",
    "    fig = plt.figure(figsize=(24, 8*len(clfs)))\n",
    "\n",
    "    # Merge train and test set\n",
    "    X_total = np.concatenate((X_train_sel, X_test_sel), axis=0)\n",
    "    y_total = np.concatenate([y_train, y_test])\n",
    "\n",
    "    # Compute learning curves\n",
    "    for clf in clfs:\n",
    "        title = str(type(clf))\n",
    "        ax = fig.add_subplot(7, 3, num+1)\n",
    "        plot_learning_curve(clf, title, X_total, y_total, ax, ylim=(0.3, 1.01),\n",
    "                            cv=cv, train_sizes=np.linspace(0.2, 1, 5))\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine mean accuracy, balanced accuracy and AUC score per classifier\n",
    "MEAN_ACC = ACCURACY.mean()\n",
    "print(f'The mean accuracy per classifier is: \\n{MEAN_ACC}')\n",
    "MEAN_ACC_BAL = ACCURACY_BALANCED.mean()\n",
    "print(f'The mean balanced accuracy per classifier is: \\n{MEAN_ACC_BAL}')\n",
    "MEAN_AUC = AUC.mean()\n",
    "STD_AUC = AUC.std()\n",
    "print(f'The mean ROC-AUC per classifier is: \\n{MEAN_AUC}')\n",
    "print(f'The standard deviation of ROC-AUC per classifier is: \\n{STD_AUC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}