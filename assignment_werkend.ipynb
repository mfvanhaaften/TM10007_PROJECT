{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook containt the following sections:\n",
    "\n",
    "1. Installing and importing functions and packages\n",
    "\n",
    "2. Loading and splitting data\n",
    "3. Preprocessing before crossvalidation\n",
    "\n",
    "   3.1 Overview of NaN's in the dataset\n",
    "\n",
    "   3.2 Feature removal based on the number of NaN's\n",
    "\n",
    "   3.3 Patient removal based on the number of NaN's\n",
    "   \n",
    "   3.4 Evaluation of data distribution and outliers\n",
    "\n",
    "4. Function definitions\n",
    "\n",
    "    4.1 Imputation\n",
    "    \n",
    "    4.2 Scaling\n",
    "\n",
    "    4.3 Feature selection/dimensionality reduction\n",
    "\n",
    "    4.4 Hyperparameter optimization feature selection method\n",
    "\n",
    "    4.5 Randomized grid searches\n",
    "\n",
    "    4.6 Performance metrics\n",
    "\n",
    "    4.7 Learning curves\n",
    "\n",
    "5. Evaluation of feature selection methods\n",
    "\n",
    "6. Outer and inner crossvalidation\n",
    "\n",
    "7. Performance of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing and importing functions and packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import shapiro, uniform\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif, mutual_info_classif, SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from missingpy import KNNImputer\n",
    "from operator import itemgetter\n",
    "from scipy import mean\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and splitting data "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Splitting data into feature values and patient labels\n",
    "FEATURES = data.drop(columns=['label'])\n",
    "LABELS = data['label']\n",
    "\n",
    "GBM = FEATURES.loc[LABELS=='GBM']\n",
    "LGG = FEATURES.loc[LABELS=='LGG']\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing before crossvalidation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Overview of the NaN's in the dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = FEATURES.isnull().sum(axis=1)             # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = FEATURES.isnull().sum(axis=0)             # Number of NaN's per feature for GBM and LGG patients\n",
    "\n",
    "GBM_NO_NAN_COL = GBM.isnull().sum(axis=0)                    # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG.isnull().sum(axis=0)                    # Number of NaN's per feature for LGG patients\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Feature removal based on the number of NaN's. Threshold = the maximum number of NaN's in a column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "482/724 features are left in dataset\n"
    }
   ],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 30\n",
    "PERC_MISSING_LGG = 30\n",
    "\n",
    "# Define threshold of number of NaN's \n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded \n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "DATA_FEAT_SEL = FEATURES.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL.columns)}/{len(FEATURES.columns)} features are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Patient removal based on the number of NaN's. Threshold = the maximum number of NaN's in a row."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The following sample(s) is/are removed from dataset:\nTCGA-HT-7686\n166/167 samples are left in dataset\n"
    }
   ],
   "source": [
    "# Define threshold of number of NaN's above which a patient is removed\n",
    "PERC_MISSING_SAMPLE = 30\n",
    "THRESHOLD_SAMPLE = floor((PERC_MISSING_SAMPLE/100) * len(DATA_FEAT_SEL.columns))\n",
    "\n",
    "# Number of NaN's per patient after feature removal\n",
    "NO_NAN_ROW_TRAIN = DATA_FEAT_SEL.isnull().sum(axis=1)      \n",
    "\n",
    "# Initialisation\n",
    "SAMPLES_REMOVED = [] \n",
    "LABELS_SEL = LABELS\n",
    "\n",
    "# Looping over the trainingset to remove patients with a number of NaN's above the threshold\n",
    "print('The following sample(s) is/are removed from dataset:')\n",
    "for sample in NO_NAN_ROW_TRAIN[NO_NAN_ROW_TRAIN > THRESHOLD_SAMPLE].index[:]:\n",
    "    if sample:\n",
    "        print(sample)\n",
    "        SAMPLES_REMOVED.append(sample)      \n",
    "        DATA_FEAT_SEL = DATA_FEAT_SEL.drop(index=sample)\n",
    "        LABELS_SEL = LABELS_SEL.drop(index=sample)\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL)}/{len(FEATURES)} samples are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Evaluation of data distribution and outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data distribution\n",
    "\n",
    "# Impute GBM and LGG patients separately\n",
    "IMPUTER_GBM = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "IMPUTER_LGG = KNNImputer(n_neighbors=5, weights=\"distance\")        \n",
    "\n",
    "X_GBM = DATA_FEAT_SEL[LABELS_SEL=='GBM']        \n",
    "X_IMP_GBM = IMPUTER_GBM.fit_transform(X_GBM)\n",
    "\n",
    "X_LGG = DATA_FEAT_SEL[LABELS_SEL=='LGG']        \n",
    "X_IMP_LGG = IMPUTER_LGG.fit_transform(X_LGG)   \n",
    "\n",
    "# Evaluate distributions of features for GBM patients\n",
    "NO_NON_NORMAL_GBM = 0       \n",
    "FEAT_NON_NORM_GBM = list()\n",
    "\n",
    "for index, feature in enumerate(X_IMP_GBM.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value<0.05:\n",
    "        NO_NON_NORMAL_GBM += 1          # Number of non normally distributed features\n",
    "        FEAT_NON_NORM_GBM.append(index)\n",
    "\n",
    "# Evaluate distributions of features for LGG patients\n",
    "NO_NON_NORMAL_LGG = 0\n",
    "FEAT_NON_NORM_LGG = list()\n",
    "for index, feature in enumerate(X_IMP_LGG.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value<0.05:\n",
    "        NO_NON_NORMAL_LGG += 1          # Number of non normally distributed features\n",
    "        FEAT_NON_NORM_LGG.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate number of outliers per patient group (LGG and GBM), depending on the Interquartile Range (IQR)\n",
    "\n",
    "# Evaluate per GBM patient each feature\n",
    "NO_OUTLIERS_GBM = 0\n",
    "\n",
    "for patient in X_IMP_GBM:                                                                       # Loop over patients\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):                                                   # Loop over features\n",
    "        q25, q75 = np.percentile(X_IMP_GBM[:,index], 25), np.percentile(X_IMP_GBM[:,index], 75) # Determine quartiles\n",
    "        iqr = q75 - q25                                                                         # Determine interquartile range\n",
    "        cut_off = iqr * 1.5                                      # Define cut-off for outlier evaluation\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off              # Determine upper and lower bounds of feature \n",
    "        outlier = ((feature>upper) | (feature<lower))            # Determine whether patient has an exceptional feature value\n",
    "        feat_out += outlier                                      # Count number of features for which patient has exceptional feature value\n",
    "    if feat_out > 70:                                               \n",
    "        NO_OUTLIERS_GBM += 1                                     # Classify patient as outlier when he has exceptional values for > 70 features\n",
    "\n",
    "# Evaluate per LGG patient each feature\n",
    "NO_OUTLIERS_LGG = 0\n",
    "\n",
    "for patient in X_IMP_LGG:\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):\n",
    "        q25, q75 = np.percentile(X_IMP_LGG[:,index], 25), np.percentile(X_IMP_LGG[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        outlier = ((feature>upper) | (feature<lower))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS_LGG += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function definitions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit k-nearest neighbor imputer on train set and impute train and test set using this fitted imputer.\n",
    "Input: \n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "Output: \n",
    "X_train_imp: array-like, shape (n_samples, n_features)\n",
    "        Imputed train data.\n",
    "\n",
    "X_test_imp: array-like, shape (n_samples, n_features)\n",
    "        Imputed test data.\n",
    "\"\"\"\n",
    "\n",
    "def knn_impute_train_test_set(X_train, X_test):\n",
    "    imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "    imputer.fit(X_train)\n",
    "    X_train_imp = imputer.transform(X_train)\n",
    "    X_test_imp = imputer.transform(X_test)\n",
    "    return X_train_imp, X_test_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit MinMax scaler on train set and scale train and test set using this fitted scaler.\n",
    "Input: \n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "Output: \n",
    "X_train_scal: array-like, shape (n_samples, n_features)\n",
    "        Scaled train data.\n",
    "\n",
    "X_test_scal: array-like, shape (n_samples, n_features)\n",
    "        Scaled test data.\n",
    "\"\"\"\n",
    "\n",
    "def scale_train_test_set(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    return X_train_scal, X_test_scal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Feature selection/dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Univariate feature selection using the Mutual Information Criterion.\n",
    "Input: \n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "Output: \n",
    "X_train_sel: array-like, shape (n_samples, n_features_selected)\n",
    "        Training vector, where n_samples is the number of samples and \n",
    "        n_features_selected is the number of selected features.\n",
    "X_test_sel: array-like, shape (n_samples, n_features_selected)\n",
    "        Test vector, where n_samples is the number of samples and \n",
    "        n_features_selected is the number of selected features.\n",
    "selection_method.get_support: array-like\n",
    "        Indices of the feature columns dat were selected\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def select_features_univariate(X_train, y_train, X_test, k_value):\n",
    "    selection_method = SelectKBest(mutual_info_classif, k=k_value).fit(X_train, y_train)\n",
    "    X_train_sel = selection_method.transform(X_train)\n",
    "    X_test_sel = selection_method.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, selection_method.get_support(indices=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using L1 \n",
    "\"\"\"\n",
    "L1-based feature selection. \n",
    "\n",
    "Input:\n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "threshold_value: string or float\n",
    "        The threshold value to use for feature selection.\n",
    "Output:\n",
    "X_train_sel: array-like, shape (n_samples, n_features_selected)\n",
    "        Training vector, where n_samples is the number of samples and \n",
    "        n_features_selected is the number of selected features.\n",
    "X_test_sel: array-like, shape (n_samples, n_features_selected)\n",
    "        Test vector, where n_samples is the number of samples and \n",
    "        n_features_selected is the number of selected features.\n",
    "\"\"\"\n",
    "def select_features_L1(X_train, y_train, X_test, threshold_value):\n",
    "    lsvc = LinearSVC(penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True, threshold=threshold_value)\n",
    "    X_train_sel = model.transform(X_train)\n",
    "    X_test_sel = model.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using recursive feature elimination\n",
    "\n",
    "def select_features_rfecv(X_train, y_train, scoring):\n",
    "\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    optimal_number_features = list()\n",
    "\n",
    "    # classifications\n",
    "    rfecv = RFECV(\n",
    "        estimator=svc, step=1, \n",
    "        cv=StratifiedKFold(4),\n",
    "        scoring=scoring)\n",
    "    rfecv.fit(X_train, y_train)                               \n",
    "\n",
    "    optimal_number_features.append(rfecv.n_features_)\n",
    "    print(\"Optimal number of features according to rfecv: %d\" % rfecv.n_features_)\n",
    "\n",
    "    return rfecv.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(X_train, X_test, components):\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Hyperparameter optimization feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determines optimal value for a hyperparameter, e.g. the number of features \n",
    "to be selected (k), of the univariate feature selection method. The train \n",
    "set that is provided as input is dividied into train and test sets using K-Fold \n",
    "crossvalidation. The choice for the best hyperparameter value is based on the \n",
    "performance of a KNN-classifier trained with the features selected by the univariate \n",
    "feature selection. The hyperparameter value that results in the highest mean Area \n",
    "under the Receiver Operator Curve (AUC) score across the 5 folds, is selected as optimal value.\n",
    "\n",
    "Input:\n",
    "X-train: X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "\n",
    "hyperparameter_options: list of settings for the hyperparameter to be evaluated.\n",
    "\n",
    "Output:\n",
    "param_optimal: float or int, based on the variable types in hyperparameter_options\n",
    "            The value for the hyperparameter that resulted in the highest mean AUC.\n",
    "\"\"\"\n",
    "\n",
    "def select_hyperparameter_feature_selection(X_train, y_train, hyperparameter_options):\n",
    "\n",
    "    # Initialisation\n",
    "    clf_inner = KNeighborsClassifier(n_neighbors=15, weights = \"distance\")\n",
    "    skf_inner = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "    performance_param_inner = pd.DataFrame()  \n",
    "\n",
    "    # Inner crossvalidation \n",
    "    for train_index_inner, validation_index_inner in skf_inner.split(X_train, y_train):\n",
    "        # Train and validation split\n",
    "        X_train_inner, X_val_inner = np.array(X_train)[train_index_inner], np.array(X_train)[validation_index_inner]\n",
    "        y_train_inner, y_val_inner = np.array(y_train)[train_index_inner], np.array(y_train)[validation_index_inner]\n",
    "    \n",
    "        #Initialisation\n",
    "        acc_inner = dict()\n",
    "        bal_acc_inner = dict()\n",
    "        roc_auc_score_inner = dict()\n",
    "        \n",
    "        # Loop over different values for hyperparameter\n",
    "        for param in hyperparameter_options:\n",
    "            X_train_sel_inner, X_val_sel_inner, selected_indices_inner  = select_features_L1(X_train_inner,                                                                                         y_train_inner, X_val_inner, param)      \n",
    "            acc_inner[str(param)], bal_acc_inner[str(param)], roc_auc_score_inner[str(param)] = get_performance_classifier(clf_inner, X_train_sel_inner, y_train_inner, X_val_sel_inner, y_val_inner)\n",
    "        \n",
    "        performance_param_inner = performance_param_inner.append(roc_auc_score_inner, ignore_index=True)\n",
    "    \n",
    "    print(f'The performances of different hyperparameter-values across the five folds is: \\n {performance_param_inner}')\n",
    "\n",
    "    # Compute mean performance and choose optimal value for hyperparameter\n",
    "    mean_performance_param_inner = performance_param_inner.mean()\n",
    "    param_optimal = float(mean_performance_param_inner.idxmax(axis=1))\n",
    "    \n",
    "\n",
    "    return param_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 Randomized grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Random Forrest Classifier\n",
    "\n",
    "def rf_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: Random Forest Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators': [32, 64, 128, 150],\n",
    "        'max_features': ['sqrt', 'log2', 0.10, 0.25, 0.50],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'max_depth': [1,6,15,28], \n",
    "        'min_samples_leaf': [0.05, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    grid = RandomizedSearchCV(RandomForestClassifier(), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "    grid.fit(X_train, y_train)\n",
    "    rf_classifier = grid.best_estimator_\n",
    "    return rf_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for K-Nearest Neighbors Classifier\n",
    "\n",
    "def knn_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: K-Nearest Neighbors Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters = {  'n_neighbors': list(range(15,20)),\n",
    "                    'weights': [\"uniform\", \"distance\"]\n",
    "                    }\n",
    "\n",
    "    grid = RandomizedSearchCV(KNeighborsClassifier(), parameters, refit=True, verbose=0, n_iter = 10)\n",
    "    grid.fit(X_train, y_train)\n",
    "    knn_classifier = grid.best_estimator_\n",
    "    return knn_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Support Vector Machine Classifier\n",
    "\n",
    "def svm_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: SVM Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters =  {'kernel': ['linear', 'rbf', 'poly'],\n",
    "                    'C': uniform(loc=0.01, scale=5), \n",
    "                    'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    'degree': [1, 2, 3, 4, 5],\n",
    "                    'coef0': uniform(loc=0.01, scale=19.99)}\n",
    "\n",
    "    grid = RandomizedSearchCV(SVC(probability=True), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "    grid.fit(X_train, y_train)\n",
    "    svm_classifier = grid.best_estimator_\n",
    "    print(svm_classifier)\n",
    "    return svm_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train classifier and obtain its performance on an independent test set. \n",
    "\n",
    "Input:\n",
    "classifier: classifier object that can be fitted to training data.\n",
    "\n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_test: array-like, shape (n_samples) \n",
    "        Target relative to X_test for classification.\n",
    "\n",
    "Output:\n",
    "accuracy: float64\n",
    "        Accuracy of classifier.\n",
    "\n",
    "balanced_acc: float64\n",
    "        Balanced accuracy of classifier.\n",
    "\n",
    "roc_auc: float64\n",
    "        Area under the receiver operator curve of classifier.\n",
    "\"\"\"\n",
    "\n",
    "def get_performance_classifier(classifier, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    prediction = classifier.predict(X_test)\n",
    "\n",
    "    # Obtain probabilities of prediction\n",
    "    order_classes = list(classifier.classes_)\n",
    "    positive_class = order_classes.index('LGG')\n",
    "    probability = classifier.predict_proba(X_test)[:,positive_class]\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "    balanced_acc = metrics.balanced_accuracy_score(y_test, prediction)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, probability)\n",
    "\n",
    "    return accuracy, balanced_acc, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.7 Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores  = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "\n",
    "    return plt\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fold 1 of evaluation of feature selection methods\nOptimal number of features according to rfecv: 20\nOptimal number of features according to rfecv: 20\nOptimal number of features according to rfecv: 20\nFold 2 of evaluation of feature selection methods\nOptimal number of features according to rfecv: 20\nOptimal number of features according to rfecv: 12\nOptimal number of features according to rfecv: 1\nFold 3 of evaluation of feature selection methods\nOptimal number of features according to rfecv: 79\nOptimal number of features according to rfecv: 6\nOptimal number of features according to rfecv: 72\nFold 4 of evaluation of feature selection methods\nOptimal number of features according to rfecv: 17\nOptimal number of features according to rfecv: 5\nOptimal number of features according to rfecv: 8\nFold 5 of evaluation of feature selection methods\nOptimal number of features according to rfecv: 8\nOptimal number of features according to rfecv: 14\nOptimal number of features according to rfecv: 14\n"
    }
   ],
   "source": [
    "#-------------------------- Cross Validation Feature Selection---------------------------------------------------\n",
    "skf_eval_sel = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "dict_uni = {'20': [], '35': [], '50': []}\n",
    "dict_rfecv = {'roc_auc': [], 'accuracy': [], 'balanced_accuracy': []}\n",
    "dict_L1 = {'1e-05': [], '0.001': [], '0.01': []}\n",
    "dict_pca = {'5': [], '10': [], '20': []}\n",
    "fold_sel = 0\n",
    "\n",
    "for train_index, test_index in skf_eval_sel.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    fold_sel += 1\n",
    "    print(f'Fold {fold_sel} of evaluation of feature selection methods')\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "    X_train_imp, X_test_imp = knn_impute_train_test_set(X_train, X_test)\n",
    "    X_train_scal, X_test_scal = scale_train_test_set(X_train_imp, X_test_imp)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "\n",
    "    # selected features univariate\n",
    "    list_uni = [20,35,50]\n",
    "    for number in list_uni:\n",
    "        X_train_sel, X_test_sel, selected_indices = select_features_univariate(X_train_scal, y_train, X_test_scal, number)\n",
    "        acc_uni, bal_acc_uni, roc_uni = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "        dict_uni[str(number)].append(roc_uni)\n",
    "\n",
    "    #selected features rfecv\n",
    "    list_rfecv = ['roc_auc','accuracy','balanced_accuracy']\n",
    "    for scoring in list_rfecv:\n",
    "        selected_features = select_features_rfecv(X_train_scal, y_train, scoring)\n",
    "        X_train_sel = X_train_scal[:,selected_features]\n",
    "        X_test_sel = X_test_scal[:,selected_features]\n",
    "        acc_rfecv, bal_acc_rfecv, roc_rfecv = get_performance_classifier(clf, X_train_sel, y_train,                                                                                              X_test_sel, y_test)\n",
    " \n",
    "        dict_rfecv[scoring].append(roc_rfecv)\n",
    "\n",
    "    list_L1 = [0.00001, 0.001, 0.01]\n",
    "    for value in list_L1:\n",
    "        X_train_sel, X_test_sel, selected_indices = select_features_L1(X_train_scal, y_train, X_test_scal, value)\n",
    "        acc_L1, bal_acc_L1, roc_L1 = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)   \n",
    "\n",
    "  \n",
    "        dict_L1[str(value)].append(roc_L1)   \n",
    "\n",
    "    #selected features pca\n",
    "    list_pca = [5, 10, 20]\n",
    "    for component in list_pca:\n",
    "       X_train_sel, X_test_sel = pca_analysis(X_train_scal, X_test_scal, component)\n",
    "       acc_pca, bal_acc_pca, roc_pca = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "       dict_pca[str(component)].append(roc_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean ROC of univariatie, 20 best: 0.9282356532356533\nMean ROC of univariatie, 35 best: 0.9224297924297924\nMean ROC of univariatie, 50 best: 0.9215750915750917\nMean ROC of RFECV, roc_auc scoring: 0.9087301587301588\nMean ROC of RFECV, accuracy scoring: 0.8954456654456655\nMean ROC of RFECV, balanced_accuracy scoring: 0.886959706959707\nMean ROC of L1, threshold of 1e-05: 0.9161477411477412\nMean ROC of L1, threshold of 0.001: 0.924072039072039\nMean ROC of L1, threshold of 0.01: 0.9128998778998779\nMean ROC of PCA, 5 components: 0.8522954822954822\nMean ROC of PCA, 10 components: 0.8831013431013431\nMean ROC of PCA, 20 components: 0.9037484737484738\n"
    }
   ],
   "source": [
    "# Evaluate the different feature selection methods by comparing ROC\n",
    "for key, values in dict_uni.items():\n",
    "    mean_values = mean(values)\n",
    "    print(f'Mean ROC of univariatie, {key} best: {mean_values}')\n",
    "for key, values in dict_rfecv.items():\n",
    "    mean_values = mean(values)\n",
    "    print(f'Mean ROC of RFECV, {key} scoring: {mean_values}')\n",
    "for key, values in dict_L1.items():\n",
    "    mean_values = mean(values)\n",
    "    print(f'Mean ROC of L1, threshold of {key}: {mean_values}')\n",
    "for key, values in dict_pca.items():\n",
    "    mean_values = mean(values)\n",
    "    print(f'Mean ROC of PCA, {key} components: {mean_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outer and inner crossvalidation "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n \n Run 1 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.935294  0.935294  0.941176  0.952941  0.935294\n1  0.948864  0.931818  0.909091  0.886364  0.914773\n2  0.934375  0.940625  0.975000  0.900000  0.928125\n3  0.993750  0.993750  0.987500  1.000000  0.987500\n4  1.000000  1.000000  1.000000  1.000000  1.000000\nThe optimal threshold value for fold 1 is: 0.1\nThe column indices of the selected features for fold 1 are: \n [  6   9  17  35  36  51  54  57  88  89  95 111 112 121 157 200 204 237\n 274 338 372 401 427 430 455 481]\nSVC(C=4.893536213913088, break_ties=False, cache_size=200, class_weight=None,\n    coef0=7.918435215522546, decision_function_shape='ovr', degree=2, gamma=100,\n    kernel='linear', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.7352941176470589, 'RF': 0.7647058823529411, 'KNN': 0.7647058823529411}\nBalanced accuracy: \n {'SVM': 0.6831501831501832, 'RF': 0.7069597069597069, 'KNN': 0.7069597069597069}\nRoc auc score: \n {'SVM': 0.706959706959707, 'RF': 0.7545787545787547, 'KNN': 0.7472527472527473}\n\n \n Run 2 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.947059  0.947059  0.950000  0.952941  0.950000\n1  0.971591  0.965909  0.960227  0.920455  0.971591\n2  0.982955  0.994318  0.977273  0.886364  0.988636\n3  0.893750  0.893750  0.956250  0.840625  0.893750\n4  0.931250  0.962500  0.956250  0.981250  0.962500\nThe optimal threshold value for fold 2 is: 0.1\nThe column indices of the selected features for fold 2 are: \n [  5   9  10  12  17  24  28  34  35  36  54  57  93 104 111 116 119 120\n 122 124 131 150 157 197 200 206 250 337 367 400 415 476 480 481]\nSVC(C=4.454948604895628, break_ties=False, cache_size=200, class_weight=None,\n    coef0=5.23984544384868, decision_function_shape='ovr', degree=3,\n    gamma=0.001, kernel='linear', max_iter=-1, probability=True,\n    random_state=None, shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.8484848484848485, 'RF': 0.8787878787878788, 'KNN': 0.8787878787878788}\nBalanced accuracy: \n {'SVM': 0.8273809523809523, 'RF': 0.8511904761904762, 'KNN': 0.8511904761904762}\nRoc auc score: \n {'SVM': 0.876984126984127, 'RF': 0.9047619047619048, 'KNN': 0.8908730158730158}\n\n \n Run 3 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.894118  0.894118  0.923529  0.888235  0.894118\n1  0.929412  0.905882  0.905882  0.861765  0.905882\n2  0.960227  0.965909  0.920455  1.000000  0.954545\n3  0.853125  0.853125  0.843750  0.737500  0.825000\n4  0.912500  0.937500  0.937500  0.868750  0.937500\nThe optimal threshold value for fold 3 is: 0.001\nThe column indices of the selected features for fold 3 are: \n [  5   9  12  17  22  23  24  28  33  35  51  58  66  73  77  87  93  95\n 102 110 113 120 121 124 129 131 132 163 197 200 206 222 250 264 289 354\n 367 372 379 429 430 455 477 478 479 481]\nSVC(C=3.4718651992812735, break_ties=False, cache_size=200, class_weight=None,\n    coef0=8.496236391675305, decision_function_shape='ovr', degree=5, gamma=1,\n    kernel='linear', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.8787878787878788, 'RF': 0.9090909090909091, 'KNN': 0.9090909090909091}\nBalanced accuracy: \n {'SVM': 0.8730769230769231, 'RF': 0.898076923076923, 'KNN': 0.898076923076923}\nRoc auc score: \n {'SVM': 0.9346153846153846, 'RF': 0.9730769230769232, 'KNN': 0.9461538461538461}\n\n \n Run 4 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.941176  0.923529  0.917647  0.841176  0.929412\n1  0.982353  0.958824  0.970588  0.935294  0.982353\n2  0.892045  0.926136  0.926136  0.965909  0.937500\n3  0.828125  0.837500  0.821875  0.778125  0.850000\n4  0.956250  0.943750  0.943750  0.931250  0.943750\nThe optimal threshold value for fold 4 is: 1e-05\nThe column indices of the selected features for fold 4 are: \n [  9  11  12  17  24  28  33  34  35  43  45  51  55  58  62  68  74  88\n  93  95 110 120 121 129 145 197 200 206 209 235 250 337 338 354 379 401\n 427 429 430 448 455 478 481]\nSVC(C=3.9221387351369157, break_ties=False, cache_size=200, class_weight=None,\n    coef0=5.1123034111840715, decision_function_shape='ovr', degree=5, gamma=10,\n    kernel='poly', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.9393939393939394, 'RF': 0.9393939393939394, 'KNN': 0.9696969696969697}\nBalanced accuracy: \n {'SVM': 0.9365384615384615, 'RF': 0.9365384615384615, 'KNN': 0.9615384615384616}\nRoc auc score: \n {'SVM': 0.9576923076923077, 'RF': 0.9961538461538462, 'KNN': 0.9961538461538462}\n\n \n Run 5 of outer crossvalidation\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(107, 0)) while a minimum of 1 is required.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1fc15e5271a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mthreshold_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mthreshold_optimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_hyperparameter_feature_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The optimal threshold value for fold {fold} is: {threshold_optimal}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d0be400c95c8>\u001b[0m in \u001b[0;36mselect_hyperparameter_feature_selection\u001b[0;34m(X_train, y_train, hyperparameter_options)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyperparameter_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mX_train_sel_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_sel_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_indices_inner\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mselect_features_L1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_inner\u001b[0m\u001b[0;34m,\u001b[0m                                                                                         \u001b[0my_train_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0macc_inner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbal_acc_inner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score_inner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_performance_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_sel_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_sel_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mperformance_param_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_param_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d4e85cf784f2>\u001b[0m in \u001b[0;36mget_performance_classifier\u001b[0;34m(classifier, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_performance_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \"\"\"\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    592\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                              % (n_features, array.shape, ensure_min_features,\n\u001b[0;32m--> 594\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(107, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "\n",
    "skf_outer = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "# Initialization\n",
    "FEATURES_SELECTED_TOTAL = list()\n",
    "fold = 0\n",
    "\n",
    "# Create dataframes\n",
    "ACCURACY = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "ACCURACY_BALANCED = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "AUC = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "\n",
    "\n",
    "for train_index, test_index in skf_outer.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    fold += 1 \n",
    "    print(f'\\n \\n Run {fold} of outer crossvalidation')\n",
    "\n",
    "    # Split data into train and test set for outer crossvalidation\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "\n",
    "\n",
    "    # ---------------------------------- IMPUTATION -----------------------------------\n",
    "\n",
    "    X_train_imp, X_test_imp = knn_impute_train_test_set(X_train, X_test)\n",
    " \n",
    "    # ------------------------------------ SCALING ----------------------------------------\n",
    "    X_train_scal, X_test_scal = scale_train_test_set(X_train_imp, X_test_imp)\n",
    "\n",
    "    # ------------------------------------ FEATURE SELECTION -------------------------------\n",
    "\n",
    "    # Determining optimal number of features k \n",
    "    #k_options = [20, 30, 40, 50]\n",
    "    #k_optimal = select_hyperparameter_feature_selection(X_train_scal, y_train, k_options)\n",
    "    #print(f'The optimal k value for fold {fold} is: {k_optimal}')\n",
    "\n",
    "    threshold_options = [0.00001, 0.0001, 0.001, 0.1, 1]\n",
    "    threshold_optimal = select_hyperparameter_feature_selection(X_train_scal, y_train, threshold_options)\n",
    "    print(f'The optimal threshold value for fold {fold} is: {threshold_optimal}')\n",
    "\n",
    "    # Univariate feature selection\n",
    "    X_train_sel, X_test_sel, selected_indices = select_features_L1(X_train_scal, y_train, X_test_scal, threshold_value=threshold_optimal)\n",
    "\n",
    "    print(f'The column indices of the selected features for fold {fold} are: \\n {selected_indices}')\n",
    "\n",
    "    # Determine names of features that were selected\n",
    "    features_selected = list()\n",
    "    for index in selected_indices:\n",
    "        features_selected.append(DATA_FEAT_SEL.columns[index])\n",
    "    FEATURES_SELECTED_TOTAL.append(features_selected)\n",
    "\n",
    "    # -------------- INNER CROSSVALIDATION FOR DETERMINATION OF HYPERPARAMETERS OF CLASSIFIERS ---------------------------------\n",
    "    svm_classifier = svm_randomized_search(X_train_sel, y_train)   \n",
    "\n",
    "    rf_classifier = rf_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    knn_classifier = knn_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    clfs = [svm_classifier, rf_classifier, knn_classifier]\n",
    "    clfs_names = ['SVM', 'RF', 'KNN']\n",
    "\n",
    "    # ---------------- TRAIN AND TEST CLASSIFIERS (OUTER CROSSVALIDATION) ------------------------------------------------\n",
    "    # Initialisation\n",
    "    acc_dict = dict()\n",
    "    accuracy_total = list()\n",
    "\n",
    "    bal_acc_dict = dict()\n",
    "    bal_acc_total = list()\n",
    "\n",
    "    roc_auc_score_dict = dict()\n",
    "    roc_auc_score_total = list()\n",
    "\n",
    "    # Determine performance\n",
    "    for clf, name in zip(clfs, clfs_names):\n",
    "        acc_dict[name], bal_acc_dict[name], roc_auc_score_dict[name] = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "\n",
    "    accuracy_total.append(acc_dict)\n",
    "    bal_acc_total.append(bal_acc_dict)\n",
    "    roc_auc_score_total.append(roc_auc_score_dict)\n",
    "    \n",
    "    ACCURACY = ACCURACY.append(acc_dict, ignore_index=True)\n",
    "    ACCURACY_BALANCED = ACCURACY_BALANCED.append(bal_acc_dict, ignore_index=True)\n",
    "    AUC = AUC.append(roc_auc_score_dict, ignore_index=True)\n",
    "\n",
    "    print(f'Regular accuracy: \\n {acc_dict}')\n",
    "    print(f'Balanced accuracy: \\n {bal_acc_dict}')\n",
    "    print(f'Roc auc score: \\n {roc_auc_score_dict}')\n",
    "\n",
    "    #-------------------- LEARNING CURVES --------------------------------------------------\n",
    "    # Initialisation\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=None)\n",
    "    num = 0\n",
    "    fig = plt.figure(figsize=(24,8*len(clfs)))\n",
    "\n",
    "    # Merge LGG and GBM patients\n",
    "    X_total = np.concatenate((X_train_sel, X_test_sel), axis=0)\n",
    "    y_total = np.concatenate([y_train, y_test])\n",
    "    \n",
    "    # Compute learning curves\n",
    "    for clf in clfs:\n",
    "        title = str(type(clf))\n",
    "        ax = fig.add_subplot(7, 3, num+1)\n",
    "        plot_learning_curve(clf, title, X_total, y_total, ax, ylim=(0.3, 1.01), cv=cv, train_sizes=np.linspace(0.2,                             1,5))\n",
    "        num += 1\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The mean accuracy per classifier is: \nSVM    0.850490\nRF     0.872995\nKNN    0.880570\ndtype: float64\nThe mean balanced accuracy per classifier is: \nSVM    0.830037\nRF     0.848191\nKNN    0.854441\ndtype: float64\nThe mean AUC per classifier is: \nSVM    0.869063\nRF     0.907143\nKNN    0.895108\ndtype: float64\n"
    }
   ],
   "source": [
    "# Determine mean accuracy, balanced accuracy and AUC score per classifier\n",
    "MEAN_ACC = ACCURACY.mean()\n",
    "print(f'The mean accuracy per classifier is: \\n{MEAN_ACC}')\n",
    "MEAN_ACC_BAL = ACCURACY_BALANCED.mean()\n",
    "print(f'The mean balanced accuracy per classifier is: \\n{MEAN_ACC_BAL}')\n",
    "MEAN_AUC = AUC.mean()\n",
    "print(f'The mean AUC per classifier is: \\n{MEAN_AUC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}