{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook containt the following sections:\n",
    "\n",
    "1. Installing and importing functions and packages\n",
    "\n",
    "2. Loading and splitting data\n",
    "3. Preprocessing before crossvalidation\n",
    "\n",
    "   3.1 Overview of NaN's in the dataset\n",
    "\n",
    "   3.2 Feature removal based on the number of NaN's\n",
    "\n",
    "   3.3 Patient removal based on the number of NaN's\n",
    "   \n",
    "   3.4 Evaluation of data distribution and outliers\n",
    "\n",
    "4. Function definitions\n",
    "\n",
    "    4.1 Imputation\n",
    "    \n",
    "    4.2 Scaling\n",
    "\n",
    "    4.3 Feature selection/dimensionality reduction\n",
    "\n",
    "    4.4 Hyperparameter optimization feature selection method\n",
    "\n",
    "    4.5 Randomized grid searches\n",
    "\n",
    "    4.6 Performance metrics\n",
    "\n",
    "    4.7 Learning curves\n",
    "\n",
    "5. Evaluation of feature selection methods\n",
    "\n",
    "6. Outer and inner crossvalidation\n",
    "\n",
    "7. Performance of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing and importing functions and packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import shapiro, uniform\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif, mutual_info_classif, SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from missingpy import KNNImputer\n",
    "from operator import itemgetter\n",
    "from scipy import mean\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and splitting data "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Splitting data into feature values and patient labels\n",
    "FEATURES = data.drop(columns=['label'])\n",
    "LABELS = data['label']\n",
    "\n",
    "GBM = FEATURES.loc[LABELS=='GBM']\n",
    "LGG = FEATURES.loc[LABELS=='LGG']\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing before crossvalidation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Overview of the NaN's in the dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = FEATURES.isnull().sum(axis=1)             # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = FEATURES.isnull().sum(axis=0)             # Number of NaN's per feature for GBM and LGG patients\n",
    "\n",
    "GBM_NO_NAN_COL = GBM.isnull().sum(axis=0)                    # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG.isnull().sum(axis=0)                    # Number of NaN's per feature for LGG patients\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Feature removal based on the number of NaN's. Threshold = the maximum number of NaN's in a column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "482/724 features are left in dataset\n"
    }
   ],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 30\n",
    "PERC_MISSING_LGG = 30\n",
    "\n",
    "# Define threshold of number of NaN's \n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded \n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "DATA_FEAT_SEL = FEATURES.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL.columns)}/{len(FEATURES.columns)} features are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Patient removal based on the number of NaN's. Threshold = the maximum number of NaN's in a row."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The following sample(s) is/are removed from dataset:\nTCGA-HT-7686\n166/167 samples are left in dataset\n"
    }
   ],
   "source": [
    "# Define threshold of number of NaN's above which a patient is removed\n",
    "PERC_MISSING_SAMPLE = 30\n",
    "THRESHOLD_SAMPLE = floor((PERC_MISSING_SAMPLE/100) * len(DATA_FEAT_SEL.columns))\n",
    "\n",
    "# Number of NaN's per patient after feature removal\n",
    "NO_NAN_ROW_TRAIN = DATA_FEAT_SEL.isnull().sum(axis=1)      \n",
    "\n",
    "# Initialisation\n",
    "SAMPLES_REMOVED = [] \n",
    "LABELS_SEL = LABELS\n",
    "\n",
    "# Looping over the trainingset to remove patients with a number of NaN's above the threshold\n",
    "print('The following sample(s) is/are removed from dataset:')\n",
    "for sample in NO_NAN_ROW_TRAIN[NO_NAN_ROW_TRAIN > THRESHOLD_SAMPLE].index[:]:\n",
    "    if sample:\n",
    "        print(sample)\n",
    "        SAMPLES_REMOVED.append(sample)      \n",
    "        DATA_FEAT_SEL = DATA_FEAT_SEL.drop(index=sample)\n",
    "        LABELS_SEL = LABELS_SEL.drop(index=sample)\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL)}/{len(FEATURES)} samples are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Evaluation of data distribution and outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data distribution\n",
    "\n",
    "# Impute GBM and LGG patients separately\n",
    "IMPUTER_GBM = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "IMPUTER_LGG = KNNImputer(n_neighbors=5, weights=\"distance\")        \n",
    "\n",
    "X_GBM = DATA_FEAT_SEL[LABELS_SEL=='GBM']        \n",
    "X_IMP_GBM = IMPUTER_GBM.fit_transform(X_GBM)\n",
    "\n",
    "X_LGG = DATA_FEAT_SEL[LABELS_SEL=='LGG']        \n",
    "X_IMP_LGG = IMPUTER_LGG.fit_transform(X_LGG)   \n",
    "\n",
    "# Evaluate distributions of features for GBM patients\n",
    "NO_NON_NORMAL_GBM = 0       \n",
    "FEAT_NON_NORM_GBM = list()\n",
    "\n",
    "for index, feature in enumerate(X_IMP_GBM.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value<0.05:\n",
    "        NO_NON_NORMAL_GBM += 1          # Number of non normally distributed features\n",
    "        FEAT_NON_NORM_GBM.append(index)\n",
    "\n",
    "# Evaluate distributions of features for LGG patients\n",
    "NO_NON_NORMAL_LGG = 0\n",
    "FEAT_NON_NORM_LGG = list()\n",
    "for index, feature in enumerate(X_IMP_LGG.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value<0.05:\n",
    "        NO_NON_NORMAL_LGG += 1          # Number of non normally distributed features\n",
    "        FEAT_NON_NORM_LGG.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate number of outliers per patient group (LGG and GBM), depending on the Interquartile Range (IQR)\n",
    "\n",
    "# Evaluate per GBM patient each feature\n",
    "NO_OUTLIERS_GBM = 0\n",
    "\n",
    "for patient in X_IMP_GBM:                                                                       # Loop over patients\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):                                                   # Loop over features\n",
    "        q25, q75 = np.percentile(X_IMP_GBM[:,index], 25), np.percentile(X_IMP_GBM[:,index], 75) # Determine quartiles\n",
    "        iqr = q75 - q25                                                                         # Determine interquartile range\n",
    "        cut_off = iqr * 1.5                                      # Define cut-off for outlier evaluation\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off              # Determine upper and lower bounds of feature \n",
    "        outlier = ((feature>upper) | (feature<lower))            # Determine whether patient has an exceptional feature value\n",
    "        feat_out += outlier                                      # Count number of features for which patient has exceptional feature value\n",
    "    if feat_out > 70:                                               \n",
    "        NO_OUTLIERS_GBM += 1                                     # Classify patient as outlier when he has exceptional values for > 70 features\n",
    "\n",
    "# Evaluate per LGG patient each feature\n",
    "NO_OUTLIERS_LGG = 0\n",
    "\n",
    "for patient in X_IMP_LGG:\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):\n",
    "        q25, q75 = np.percentile(X_IMP_LGG[:,index], 25), np.percentile(X_IMP_LGG[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        outlier = ((feature>upper) | (feature<lower))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS_LGG += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function definitions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit k-nearest neighbor imputer on train set and impute train and test set using this fitted imputer.\n",
    "Input: \n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "Output: \n",
    "X_train_imp: array-like, shape (n_samples, n_features)\n",
    "        Imputed train data.\n",
    "\n",
    "X_test_imp: array-like, shape (n_samples, n_features)\n",
    "        Imputed test data.\n",
    "\"\"\"\n",
    "\n",
    "def knn_impute_train_test_set(X_train, X_test):\n",
    "    imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "    imputer.fit(X_train)\n",
    "    X_train_imp = imputer.transform(X_train)\n",
    "    X_test_imp = imputer.transform(X_test)\n",
    "    return X_train_imp, X_test_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit MinMax scaler on train set and scale train and test set using this fitted scaler.\n",
    "Input: \n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "Output: \n",
    "X_train_scal: array-like, shape (n_samples, n_features)\n",
    "        Scaled train data.\n",
    "\n",
    "X_test_scal: array-like, shape (n_samples, n_features)\n",
    "        Scaled test data.\n",
    "\"\"\"\n",
    "\n",
    "def scale_train_test_set(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    return X_train_scal, X_test_scal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Feature selection/dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Univariate feature selection using the Mutual Information Criterion.\n",
    "Input: \n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "Output: \n",
    "X_train_scal: array-like, shape (n_samples, n_features_selected)\n",
    "        Training vector, where n_samples is the number of samples and \n",
    "        n_features_selected is the number of selected features.\n",
    "X_test_scal: array-like, shape (n_samples, n_features_selected)\n",
    "        Test vector, where n_samples is the number of samples and \n",
    "        n_features_selected is the number of selected features.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def select_features_univariate(X_train, y_train, X_test, k_value):\n",
    "    selection_method = SelectKBest(mutual_info_classif, k=k_value).fit(X_train, y_train)\n",
    "    X_train_sel = selection_method.transform(X_train)\n",
    "    X_test_sel = selection_method.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, selection_method.get_support(indices=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using L1 \n",
    "\n",
    "def select_features_L1(X_train, y_train, X_test, threshold_value):\n",
    "    lsvc = LinearSVC(penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True, threshold=t, max_features=20hreshold_value)\n",
    "    X_train_sel = model.transform(X_train)\n",
    "    X_test_sel = model.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using recursive feature elimination\n",
    "\n",
    "def select_features_rfecv(X_train, y_train, scoring):\n",
    "\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    optimal_number_features = list()\n",
    "\n",
    "    # classifications\n",
    "    rfecv = RFECV(\n",
    "        estimator=svc, step=1, \n",
    "        cv=StratifiedKFold(4),\n",
    "        scoring=scoring)\n",
    "    rfecv.fit(X_train, y_train)                               \n",
    "\n",
    "    optimal_number_features.append(rfecv.n_features_)\n",
    "    print(\"Optimal number of features according to rfecv: %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    #plt.figure()\n",
    "    #plt.xlabel(\"Number of features selected\")\n",
    "    #plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    #plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    #plt.show()\n",
    "\n",
    "    return rfecv.support_\n",
    "    #print(rfecv.ranking_)\n",
    "    #np.absolute(rfecv.estimator_.coef_)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(X_train, X_test, components):\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Hyperparameter optimization feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determines optimal value for a hyperparameter, e.g. the number of features \n",
    "to be selected (k), of the univariate feature selection method. The train \n",
    "set that is provided as input is dividied into train and test sets using K-Fold \n",
    "crossvalidation. The choice for the best hyperparameter value is based on the \n",
    "performance of a KNN-classifier trained with the features selected by the univariate \n",
    "feature selection. The hyperparameter value that results in the highest mean Area \n",
    "under the Receiver Operator Curve (AUC) score across the 5 folds, is selected as optimal value.\n",
    "\n",
    "Input:\n",
    "X-train: X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "\n",
    "hyperparameter_options: list of settings for the hyperparameter to be evaluated.\n",
    "\n",
    "Output:\n",
    "param_optimal: float or int, based on the variable types in hyperparameter_options\n",
    "            The value for the hyperparameter that resulted in the highest mean AUC.\n",
    "\"\"\"\n",
    "\n",
    "def select_hyperparameter_feature_selection(X_train, y_train, hyperparameter_options):\n",
    "\n",
    "    # Initialisation\n",
    "    clf_inner = KNeighborsClassifier(n_neighbors=15, weights = \"distance\")\n",
    "    skf_inner = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "    performance_param_inner = pd.DataFrame()  \n",
    "\n",
    "    # Inner crossvalidation \n",
    "    for train_index_inner, validation_index_inner in skf_inner.split(X_train, y_train):\n",
    "        # Train and validation split\n",
    "        X_train_inner, X_val_inner = np.array(X_train)[train_index_inner], np.array(X_train)[validation_index_inner]\n",
    "        y_train_inner, y_val_inner = np.array(y_train)[train_index_inner], np.array(y_train)[validation_index_inner]\n",
    "    \n",
    "        #Initialisation\n",
    "        acc_inner = dict()\n",
    "        bal_acc_inner = dict()\n",
    "        roc_auc_score_inner = dict()\n",
    "        \n",
    "        # Loop over different values for hyperparameter\n",
    "        for param in hyperparameter_options:\n",
    "            X_train_sel_inner, X_val_sel_inner, selected_indices_inner  = select_features_L1(X_train_inner,                                                                                         y_train_inner, X_val_inner, param)      \n",
    "            acc_inner[str(param)], bal_acc_inner[str(param)], roc_auc_score_inner[str(param)] = get_performance_classifier(clf_inner, X_train_sel_inner, y_train_inner, X_val_sel_inner, y_val_inner)\n",
    "        \n",
    "        performance_param_inner = performance_param_inner.append(roc_auc_score_inner, ignore_index=True)\n",
    "    \n",
    "    print(f'The performances of different hyperparameter-values across the five folds is: \\n {performance_param_inner}')\n",
    "\n",
    "    # Compute mean performance and choose optimal value for hyperparameter\n",
    "    mean_performance_param_inner = performance_param_inner.mean()\n",
    "    param_optimal = float(mean_performance_param_inner.idxmax(axis=1))\n",
    "    \n",
    "\n",
    "    return param_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 Randomized grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Random Forrest Classifier\n",
    "\n",
    "def rf_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: Random Forest Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators': [32, 64, 128, 150],\n",
    "        'max_features': ['sqrt', 'log2', 0.10, 0.25, 0.50],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'max_depth': [1,6,15,28], \n",
    "        'min_samples_leaf': [0.05, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    grid = RandomizedSearchCV(RandomForestClassifier(), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "    grid.fit(X_train, y_train)\n",
    "    rf_classifier = grid.best_estimator_\n",
    "    return rf_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for K-Nearest Neighbors Classifier\n",
    "\n",
    "def knn_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: K-Nearest Neighbors Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters = {  'n_neighbors': list(range(15,20)),\n",
    "                    'weights': [\"uniform\", \"distance\"]\n",
    "                    }\n",
    "\n",
    "    grid = RandomizedSearchCV(KNeighborsClassifier(), parameters, refit=True, verbose=0, n_iter = 10)\n",
    "    grid.fit(X_train, y_train)\n",
    "    knn_classifier = grid.best_estimator_\n",
    "    return knn_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Support Vector Machine Classifier\n",
    "\n",
    "def svm_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: SVM Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters =  {'kernel': ['linear', 'rbf', 'poly'],\n",
    "                    'C': uniform(loc=0.01, scale=5), \n",
    "                    'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    'degree': [1, 2, 3, 4, 5],\n",
    "                    'coef0': uniform(loc=0.01, scale=19.99)}\n",
    "\n",
    "    grid = RandomizedSearchCV(SVC(probability=True), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "    grid.fit(X_train, y_train)\n",
    "    svm_classifier = grid.best_estimator_\n",
    "    print(svm_classifier)\n",
    "    return svm_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train classifier and obtain its performance on an independent test set. \n",
    "\n",
    "Input:\n",
    "classifier: classifier object that can be fitted to training data.\n",
    "\n",
    "X_train : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_train: array-like, shape (n_samples) \n",
    "        Target relative to X_train for classification.\n",
    "X_test : array-like, shape (n_samples, n_features)\n",
    "        Test vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "y_test: array-like, shape (n_samples) \n",
    "        Target relative to X_test for classification.\n",
    "\n",
    "Output:\n",
    "accuracy: float64\n",
    "        Accuracy of classifier.\n",
    "\n",
    "balanced_acc: float64\n",
    "        Balanced accuracy of classifier.\n",
    "\n",
    "roc_auc: float64\n",
    "        Area under the receiver operator curve of classifier.\n",
    "\"\"\"\n",
    "\n",
    "def get_performance_classifier(classifier, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    prediction = classifier.predict(X_test)\n",
    "\n",
    "    # Obtain probabilities of prediction\n",
    "    order_classes = list(classifier.classes_)\n",
    "    positive_class = order_classes.index('LGG')\n",
    "    probability = classifier.predict_proba(X_test)[:,positive_class]\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "    balanced_acc = metrics.balanced_accuracy_score(y_test, prediction)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, probability)\n",
    "\n",
    "    return accuracy, balanced_acc, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.7 Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores  = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "\n",
    "    return plt\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------New definitions for choosing the feature selection method------------\n",
    "# Univariate feature selection with different number of Selected Best\n",
    "def univariate_fs(X_train, y_train, X_test, K_neighbors):\n",
    "    selection_method = SelectKBest(f_classif, k=K_neighbors).fit(X_train, y_train)\n",
    "    X_train_sel = selection_method.transform(X_train)\n",
    "    X_test_sel = selection_method.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, selection_method.get_support(indices=True)   \n",
    "\n",
    "# Recursive feature elimination with different step size\n",
    "def rfecv_fs(X_train, y_train,scoring):\n",
    "\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    optimal_number_features = list()\n",
    "\n",
    "    # classifications\n",
    "    rfecv = RFECV(\n",
    "        estimator=svc, step=1, \n",
    "        cv=StratifiedKFold(4),\n",
    "        scoring=scoring)\n",
    "    rfecv.fit(X_train, y_train)                               \n",
    "\n",
    "    optimal_number_features.append(rfecv.n_features_)\n",
    "    #print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    #plt.figure()\n",
    "    #plt.xlabel(\"Number of features selected\")\n",
    "    #plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    #plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    #plt.show()\n",
    "\n",
    "    return rfecv.support_\n",
    "    #print(rfecv.ranking_)\n",
    "    #np.absolute(rfecv.estimator_.coef_)\n",
    "\n",
    "\n",
    "\n",
    "# L1 with different C-values\n",
    "def L1_fs(X_train, y_train, X_test,threshold_value):\n",
    "    lsvc = LinearSVC(penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True, threshold = threshold_value)\n",
    "    X_train_sel = model.transform(X_train)\n",
    "    X_test_sel = model.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, model.get_support(indices=True)\n",
    "\n",
    "# PCA analysis with different number of components\n",
    "def pca_analysis_fs(X_train, X_test, components):\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-60-ac277043bbd5>, line 43)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-ac277043bbd5>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    print(\"\"he column indices of the selected features for RFECV feature selection are: {selected_features}\"\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#-------------------------- Cross Validation Feature Selection---------------------------------------------------\n",
    "skf_eval_sel = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)\n",
    "\n",
    "acc_total_uni = list()\n",
    "bal_acc_total_uni = list()\n",
    "roc_total_uni = list()\n",
    "acc_total_rfecv = list()\n",
    "bal_acc_total_rfecv = list()\n",
    "roc_total_rfecv = list()\n",
    "acc_total_L1 = list()\n",
    "bal_acc_total_L1 = list()\n",
    "roc_total_L1 = list()\n",
    "acc_total_pca = list()\n",
    "bal_acc_total_pca = list()\n",
    "roc_total_pca = list()\n",
    "\n",
    "for train_index, test_index in skf_eval_sel.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "    X_train_imp, X_test_imp = knn_impute_train_test_set(X_train, X_test)\n",
    "    X_train_scal, X_test_scal = scale_train_test_set(X_train_imp, X_test_imp)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "\n",
    "    # selected features univariate\n",
    "    list_uni = (20,35,50)\n",
    "    for number in list_uni:\n",
    "        X_train_sel, X_test_sel, selected_indices = select_features_univariate(X_train_scal, y_train, X_test_scal, number)\n",
    "        acc_uni, bal_acc_uni, roc_uni = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "    \n",
    "        print(f'The column indices of the selected features for univariate feature selection are: {selected_indices}')\n",
    "        acc_total_uni.append(acc_uni)\n",
    "        bal_acc_total_uni.append(bal_acc_uni)\n",
    "        roc_total_uni.append(roc_uni)\n",
    "\n",
    "    #selected features rfecv\n",
    "    list_rfecv = ('roc_auc','accuracy','balanced_accuracy')\n",
    "    for scoring in list_rfecv:\n",
    "        selected_features = select_features_rfecv(X_train_scal, y_train, scoring)\n",
    "        X_train_sel = X_train_scal[:,selected_features]\n",
    "        X_test_sel = X_test_scal[:,selected_features]\n",
    "        acc_rfecv, bal_acc_rfecv, roc_rfecv = get_performance_classifier(clf, X_train_sel, y_train,                                                                                              X_test_sel, y_test)\n",
    "        print(\"\"he column indices of the selected features for RFECV feature selection are: {selected_features}\"\"\n",
    "\n",
    "        acc_total_rfecv.append(acc_rfecv)\n",
    "        bal_acc_total_rfecv.append(bal_acc_rfecv)\n",
    "        roc_total_rfecv.append(roc_rfecv)\n",
    "\n",
    "    ##selected features L1\n",
    "\n",
    "    list_L1 = (0.00001, 0.001, 0.01)\n",
    "    for value in list_L1:\n",
    "        X_train_sel, X_test_sel, selected_indices = select_features_L1(X_train_scal, y_train, X_test_scal, value)\n",
    "        acc_L1, bal_acc_L1, roc_L1 = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "\n",
    "        acc_total_L1.append(acc_L1)\n",
    "        bal_acc_total_L1.append(bal_acc_L1)\n",
    "        roc_total_L1.append(roc_L1)        pprint(f'The column indices of the selected features for L1 feature selection are: {selected_indices}')\n",
    "     #selected features pca\n",
    "    list_pca = (5, 10, 20)\n",
    "    for component in list_pca:\n",
    "        X_train_sel_pca, X_test_sel_pca = pca_analysis(X_train_scal, X_test_scal, component)\n",
    "        acc_pca, bal_acc_pca, roc_pca = get_performance_classifier(clf, X_train_sel_pca, y_train,                                                                                          X_test_sel_pca, y_test)\n",
    "        acc_total_pca.append(acc_pca)\n",
    "        bal_acc_total_pca.append(bal_acc_pca)\n",
    "        roc_total_pca.append(roc_pca)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0b19afb869e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# first parameter option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muni_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_total_uni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmean_uni_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muni_20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrfecv_roc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_total_rfecv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Evaluate the different feature selection methods by comparing ROC\n",
    "# first parameter option\n",
    "index_list = [0,3,6,9,12]\n",
    "uni_20 = list(itemgetter(*index_list)(roc_total_uni)) \n",
    "mean_uni_20 = mean(uni_20)\n",
    "rfecv_roc = list(itemgetter(*index_list)(roc_total_rfecv)) \n",
    "mean_rfecv_roc = mean(rfecv_roc)\n",
    "pca_5 = list(itemgetter(*index_list)(roc_total_pca)) \n",
    "mean_pca_5 = mean(pca_5)\n",
    "l1_01 = list(itemgetter(*index_list)(roc_total_L1)) \n",
    "mean_l1_01 = mean(l1_01)\n",
    "\n",
    "# second parameter option\n",
    "index_list = [1,4,7,10,13]\n",
    "uni_35 = list(itemgetter(*index_list)(roc_total_uni)) \n",
    "mean_uni_35 = mean(uni_35)\n",
    "rfecv_acc = list(itemgetter(*index_list)(roc_total_rfecv)) \n",
    "mean_rfecv_acc = mean(rfecv_acc)\n",
    "pca_10 = list(itemgetter(*index_list)(roc_total_pca)) \n",
    "mean_pca_10 = mean(pca_10)\n",
    "l1_02 = list(itemgetter(*index_list)(roc_total_L1)) \n",
    "mean_l1_02 = mean(l1_02)\n",
    "\n",
    "# third parameter option\n",
    "index_list = [2,5,8,11,14]\n",
    "uni_50 = list(itemgetter(*index_list)(roc_total_uni))\n",
    "mean_uni_50 = mean(uni_50) \n",
    "rfecv_bacc = list(itemgetter(*index_list)(roc_total_rfecv)) \n",
    "mean_rfecv_bacc = mean(rfecv_acc)\n",
    "pca_20 = list(itemgetter(*index_list)(roc_total_pca)) \n",
    "mean_pca_20 = mean(pca_20)\n",
    "l1_03 = list(itemgetter(*index_list)(roc_total_L1)) \n",
    "mean_l1_03 = mean(l1_03)\n",
    "\n",
    "print(f'Mean ROC of univariate, 20 best: {mean_uni_20}')\n",
    "print(f'Mean ROC of univariate, 35 best: {mean_uni_35}')\n",
    "print(f'Mean ROC of univariate, 50 best: {mean_uni_50}')\n",
    "print(f'Mean ROC of RFECV, roc scoring: {mean_rfecv_roc}')\n",
    "print(f'Mean ROC of RFECV, accuracy scoring: {mean_rfecv_acc}')\n",
    "print(f'Mean ROC of RFECV, balanced accuracy scoring: {mean_rfecv_bacc}')\n",
    "print(f'Mean ROC of PCA, 5 components: {mean_pca_5}')\n",
    "print(f'Mean ROC of PCA, 10 components: {mean_pca_10}')\n",
    "print(f'Mean ROC of PCA, 20 components: {mean_pca_20}')\n",
    "print(f'Mean ROC of L1, threshold of 0.00001: {mean_l1_01}')\n",
    "print(f'Mean ROC of L1, threshold of 0.001: {mean_l1_02}')\n",
    "print(f'Mean ROC of L1, threshold of 0.01: {mean_l1_03}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outer and inner crossvalidation "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n \n Run 1 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.964706  0.976471  0.970588  0.941176  0.970588\n1  0.750000  0.775568  0.750000  0.755682  0.792614\n2  0.931250  0.950000  0.931250  0.975000  0.950000\n3  0.950000  0.956250  0.906250  0.881250  0.943750\n4  0.875000  0.887500  0.878125  0.862500  0.912500\nThe optimal threshold value for fold 1 is: 1e-05\nThe column indices of the selected features for fold 1 are: \n [  9  11  12  17  24  28  35  51  57  93  95 111 121 200 239 250 351 354\n 440 481]\nSVC(C=0.41819602345378737, break_ties=False, cache_size=200, class_weight=None,\n    coef0=17.198901183437627, decision_function_shape='ovr', degree=2,\n    gamma=100, kernel='poly', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.8529411764705882, 'RF': 0.9705882352941176, 'KNN': 0.9705882352941176}\nBalanced accuracy: \n {'SVM': 0.8663003663003663, 'RF': 0.9615384615384616, 'KNN': 0.9615384615384616}\nRoc auc score: \n {'SVM': 0.9615384615384615, 'RF': 0.9706959706959708, 'KNN': 0.9908424908424909}\n\n \n Run 2 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.958824  0.923529  0.958824  0.905882  0.970588\n1  0.920455  0.931818  0.931818  0.892045  0.909091\n2  0.809659  0.821023  0.809659  0.903409  0.798295\n3  0.943750  0.937500  0.937500  0.893750  0.943750\n4  0.950000  0.950000  0.937500  0.862500  0.903125\nThe optimal threshold value for fold 2 is: 0.0001\nThe column indices of the selected features for fold 2 are: \n [  8   9  12  17  24  34  35  58  87  93 119 121 124 150 206 222 235 248\n 367 430]\nSVC(C=0.7835206337915612, break_ties=False, cache_size=200, class_weight=None,\n    coef0=1.9173359708546067, decision_function_shape='ovr', degree=4,\n    gamma=0.1, kernel='poly', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.8787878787878788, 'RF': 0.8787878787878788, 'KNN': 0.8787878787878788}\nBalanced accuracy: \n {'SVM': 0.8333333333333333, 'RF': 0.8333333333333333, 'KNN': 0.8333333333333333}\nRoc auc score: \n {'SVM': 0.8968253968253969, 'RF': 0.873015873015873, 'KNN': 0.9563492063492064}\n\n \n Run 3 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.917647  0.935294  0.917647  0.970588  0.964706\n1  0.955882  0.964706  0.958824  0.926471  0.955882\n2  0.892045  0.886364  0.937500  0.826705  0.886364\n3  0.906250  0.903125  0.903125  0.950000  0.912500\n4  0.743750  0.737500  0.756250  0.793750  0.746875\nThe optimal threshold value for fold 3 is: 0.1\nThe column indices of the selected features for fold 3 are: \n [  9  11  12  17  24  33  35  57  60  68 110 121 131 200 337 430 448 476\n 477 481]\nSVC(C=4.159624180251468, break_ties=False, cache_size=200, class_weight=None,\n    coef0=16.853349886506447, decision_function_shape='ovr', degree=5, gamma=1,\n    kernel='poly', max_iter=-1, probability=True, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\nRegular accuracy: \n {'SVM': 0.7575757575757576, 'RF': 0.8181818181818182, 'KNN': 0.8181818181818182}\nBalanced accuracy: \n {'SVM': 0.7326923076923078, 'RF': 0.8096153846153846, 'KNN': 0.8096153846153846}\nRoc auc score: \n {'SVM': 0.8500000000000001, 'RF': 0.8884615384615384, 'KNN': 0.8673076923076923}\n\n \n Run 4 of outer crossvalidation\nThe performances of different hyperparameter-values across the five folds is: \n      0.0001     0.001       0.1         1     1e-05\n0  0.964706  0.964706  0.970588  0.958824  0.964706\n1  0.894118  0.894118  0.882353  0.832353  0.897059\n2  0.835227  0.835227  0.835227  0.877841  0.835227\n3  1.000000  0.993750  1.000000  0.993750  0.993750\n4  0.950000  0.950000  0.925000  0.887500  0.925000\nThe optimal threshold value for fold 4 is: 0.0001\nThe column indices of the selected features for fold 4 are: \n [  9  12  17  35  52  58  88  93 112 114 120 121 197 250 401 417 427 429\n 430 478]\nSVC(C=4.728022372863369, break_ties=False, cache_size=200, class_weight=None,\n    coef0=8.517078909326807, decision_function_shape='ovr', degree=2,\n    gamma=0.001, kernel='linear', max_iter=-1, probability=True,\n    random_state=None, shrinking=True, tol=0.001, verbose=False)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1fc15e5271a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0msvm_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_randomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mrf_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_randomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mknn_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_randomized_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-1b9fd7ff3df8>\u001b[0m in \u001b[0;36mrf_randomized_search\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mrf_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrf_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[1;32m    368\u001b[0m                                           random_state=random_state)\n\u001b[0;32m--> 369\u001b[0;31m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    367\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[1;32m    368\u001b[0m                                           random_state=random_state)\n\u001b[0;32m--> 369\u001b[0;31m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         estimator.set_params(**{p: getattr(self, p)\n\u001b[1;32m    149\u001b[0m                                 for p in self.estimator_params})\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2831\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2833\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2282\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m   2159\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[1;32m   2160\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                                     default=defaults[offset]))\n\u001b[0m\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \u001b[0;31m# *args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \"\"\"Either returns an existing member, or creates a new enum class.\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "skf_outer = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "# Initialization\n",
    "FEATURES_SELECTED_TOTAL = list()\n",
    "fold = 0\n",
    "\n",
    "# Create dataframes\n",
    "ACCURACY = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "ACCURACY_BALANCED = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "AUC = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "\n",
    "\n",
    "for train_index, test_index in skf_outer.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    fold += 1 \n",
    "    print(f'\\n \\n Run {fold} of outer crossvalidation')\n",
    "\n",
    "    # Split data into train and test set for outer crossvalidation\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "\n",
    "\n",
    "    # ---------------------------------- IMPUTATION -----------------------------------\n",
    "\n",
    "    X_train_imp, X_test_imp = knn_impute_train_test_set(X_train, X_test)\n",
    " \n",
    "    # ------------------------------------ SCALING ----------------------------------------\n",
    "    X_train_scal, X_test_scal = scale_train_test_set(X_train_imp, X_test_imp)\n",
    "\n",
    "    # ------------------------------------ FEATURE SELECTION -------------------------------\n",
    "\n",
    "    # Determining optimal number of features k \n",
    "    #k_options = [20, 30, 40, 50]\n",
    "    #k_optimal = select_hyperparameter_feature_selection(X_train_scal, y_train, k_options)\n",
    "    #print(f'The optimal k value for fold {fold} is: {k_optimal}')\n",
    "\n",
    "    threshold_options = [0.00001, 0.0001, 0.001, 0.1, 1]\n",
    "    threshold_optimal = select_hyperparameter_feature_selection(X_train_scal, y_train, threshold_options)\n",
    "    print(f'The optimal threshold value for fold {fold} is: {threshold_optimal}')\n",
    "\n",
    "    # Univariate feature selection\n",
    "    X_train_sel, X_test_sel, selected_indices = select_features_L1(X_train_scal, y_train, X_test_scal, threshold_value=threshold_optimal)\n",
    "\n",
    "    print(f'The column indices of the selected features for fold {fold} are: \\n {selected_indices}')\n",
    "\n",
    "    # Determine names of features that were selected\n",
    "    features_selected = list()\n",
    "    for index in selected_indices:\n",
    "        features_selected.append(DATA_FEAT_SEL.columns[index])\n",
    "    FEATURES_SELECTED_TOTAL.append(features_selected)\n",
    "\n",
    "    # -------------- INNER CROSSVALIDATION FOR DETERMINATION OF HYPERPARAMETERS OF CLASSIFIERS ---------------------------------\n",
    "    svm_classifier = svm_randomized_search(X_train_sel, y_train)   \n",
    "\n",
    "    rf_classifier = rf_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    knn_classifier = knn_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    clfs = [svm_classifier, rf_classifier, knn_classifier]\n",
    "    clfs_names = ['SVM', 'RF', 'KNN']\n",
    "\n",
    "    # ---------------- TRAIN AND TEST CLASSIFIERS (OUTER CROSSVALIDATION) ------------------------------------------------\n",
    "    # Initialisation\n",
    "    acc_dict = dict()\n",
    "    accuracy_total = list()\n",
    "\n",
    "    bal_acc_dict = dict()\n",
    "    bal_acc_total = list()\n",
    "\n",
    "    roc_auc_score_dict = dict()\n",
    "    roc_auc_score_total = list()\n",
    "\n",
    "    # Determine performance\n",
    "    for clf, name in zip(clfs, clfs_names):\n",
    "        acc_dict[name], bal_acc_dict[name], roc_auc_score_dict[name] = get_performance_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "\n",
    "    accuracy_total.append(acc_dict)\n",
    "    bal_acc_total.append(bal_acc_dict)\n",
    "    roc_auc_score_total.append(roc_auc_score_dict)\n",
    "    \n",
    "    ACCURACY = ACCURACY.append(acc_dict, ignore_index=True)\n",
    "    ACCURACY_BALANCED = ACCURACY_BALANCED.append(bal_acc_dict, ignore_index=True)\n",
    "    AUC = AUC.append(roc_auc_score_dict, ignore_index=True)\n",
    "\n",
    "    print(f'Regular accuracy: \\n {acc_dict}')\n",
    "    print(f'Balanced accuracy: \\n {bal_acc_dict}')\n",
    "    print(f'Roc auc score: \\n {roc_auc_score_dict}')\n",
    "\n",
    "    #-------------------- LEARNING CURVES --------------------------------------------------\n",
    "    # Initialisation\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=None)\n",
    "    num = 0\n",
    "    fig = plt.figure(figsize=(24,8*len(clfs)))\n",
    "\n",
    "    # Merge LGG and GBM patients\n",
    "    X_total = np.concatenate((X_train_sel, X_test_sel), axis=0)\n",
    "    y_total = np.concatenate([y_train, y_test])\n",
    "    \n",
    "    # Compute learning curves\n",
    "    for clf in clfs:\n",
    "        title = str(type(clf))\n",
    "        ax = fig.add_subplot(7, 3, num+1)\n",
    "        plot_learning_curve(clf, title, X_total, y_total, ax, ylim=(0.3, 1.01), cv=cv, train_sizes=np.linspace(0.2,                             1,5))\n",
    "        num += 1\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The mean accuracy per classifier is: \nSVM    0.887701\nRF     0.917781\nKNN    0.932487\ndtype: float64\nThe mean balanced accuracy per classifier is: \nSVM    0.888141\nRF     0.905220\nKNN    0.920788\ndtype: float64\nThe mean AUC per classifier is: \nSVM    0.946108\nRF     0.956502\nKNN    0.947047\ndtype: float64\n"
    }
   ],
   "source": [
    "# Determine mean accuracy, balanced accuracy and AUC score per classifier\n",
    "MEAN_ACC = ACCURACY.mean()\n",
    "print(f'The mean accuracy per classifier is: \\n{MEAN_ACC}')\n",
    "MEAN_ACC_BAL = ACCURACY_BALANCED.mean()\n",
    "print(f'The mean balanced accuracy per classifier is: \\n{MEAN_ACC_BAL}')\n",
    "MEAN_AUC = AUC.mean()\n",
    "print(f'The mean AUC per classifier is: \\n{MEAN_AUC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}