{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing functions and packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: missingpy in c:\\users\\eigenaar\\miniconda3\\lib\\site-packages (0.2.0)\n"
    }
   ],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "#from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from missingpy import KNNImputer\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting data "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Splitting feature values and patient labels\n",
    "FEATURES = data.drop(columns=['label'])\n",
    "LABELS = data['label']\n",
    "\n",
    "# Splitting into train and test set\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(FEATURES, LABELS, test_size=0.2, random_state=42)\n",
    "\n",
    "GBM_TRAIN = X_TRAIN.loc[Y_TRAIN=='GBM']\n",
    "LGG_TRAIN = X_TRAIN.loc[Y_TRAIN=='LGG']\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the NaN's in the dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = X_TRAIN.isnull().sum(axis=1)             # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = X_TRAIN.isnull().sum(axis=0)             # Number of NaN's per feature for GBM and LGG patients\n",
    "\n",
    "GBM_NO_NAN_COL = GBM_TRAIN.isnull().sum(axis=0)             # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG_TRAIN.isnull().sum(axis=0)             # Number of NaN's per feature for LGG patients\n",
    "OVERVIEW_NAN = { 'Total': NO_NAN_COL_TOTAL, 'GBM': GBM_NO_NAN_COL, 'LGG': LGG_NO_NAN_COL } \n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection based on the number of NaN's. Threshold = the maximum number of NaN's in a column."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "These samples are removed from trainingset:\nTCGA-HT-7686\n132 samples are left in trainingset\n482 features are left in trainingset\n"
    }
   ],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 5\n",
    "PERC_MISSING_LGG = 5\n",
    "\n",
    "# Determining threshold for discarding feature based on above percentage\n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM_TRAIN.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG_TRAIN.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded to list\n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "X_TRAIN_FEAT_SEL = X_TRAIN.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "X_TEST_FEAT_SEL = X_TEST.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "# The variables (series) below 'bins' the NaN's:\n",
    "# - the index column is the amount of NaN's in the dataset \n",
    "# - the second column is the amount of features that have this amount of NaN's\n",
    "\n",
    "#aantal_NAN_GBM = GBM_no_nan_col.value_counts()\n",
    "#aantal_NAN_LGG = LGG_no_nan_col.value_counts()\n",
    "#aantal_NAN_total = no_nan_col.value_counts()\n",
    "\n",
    "##############\n",
    "\n",
    "# Number of NaN's per patient AFTER removing some features\n",
    "NO_NAN_ROW_TOTAL_2 = X_TRAIN_FEAT_SEL.isnull().sum(axis=1)      \n",
    "\n",
    "# Percentage/number of features that a patient is allowed to miss. When above this amount, this patient is removed from the trainingset, because it is missing too many features. \n",
    "PERC_MISSING_SAMPLE = 15\n",
    "\n",
    "# Make the threshold\n",
    "THRESHOLD_SAMPLE = floor((PERC_MISSING_SAMPLE/100) * len(X_TRAIN_FEAT_SEL.columns))\n",
    "\n",
    "# Make an empty list, which will be filled with samples that are above the threshold -->\n",
    "# This is only for consistency, because there is also a FEATURES_REMOVED variable.                              # It is not used anywhere else, so it can be removed if necessary. \n",
    "SAMPLES_REMOVED = []   \n",
    "\n",
    "# Looping over the trainingset to determine which patients are above the threshold, and remove them directly.\n",
    "print('These samples are removed from trainingset:')\n",
    "for sample in NO_NAN_ROW_TOTAL_2[NO_NAN_ROW_TOTAL_2 > THRESHOLD_SAMPLE].index[:]:\n",
    "    print(sample)\n",
    "    SAMPLES_REMOVED.append(sample)      # This should be removed in combination with the comment before\n",
    "    X_TRAIN_FEAT_SEL = X_TRAIN_FEAT_SEL.drop(index=sample)\n",
    "\n",
    "print(f'{len(X_TRAIN_FEAT_SEL)} samples are left in trainingset')\n",
    "print(f'{len(X_TRAIN_FEAT_SEL.columns)} features are left in trainingset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN imputation of missing values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of imputers\n",
    "IMPUTER_GBM = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "IMPUTER_LGG = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "IMPUTER_TEST = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "# Impute GBM train set\n",
    "X_TRAIN_FEAT_SEL_GBM = X_TRAIN_FEAT_SEL.loc[Y_TRAIN=='GBM']\n",
    "X_TRAIN_IMP_GBM = IMPUTER_GBM.fit_transform(X_TRAIN_FEAT_SEL_GBM)    \n",
    "\n",
    "# Impute LGG train set\n",
    "X_TRAIN_FEAT_SEL_LGG = X_TRAIN_FEAT_SEL.loc[Y_TRAIN=='LGG']\n",
    "X_TRAIN_IMP_LGG = IMPUTER_LGG.fit_transform(X_TRAIN_FEAT_SEL_LGG)    \n",
    "\n",
    "# Merge imputed GBM and LGG arrays\n",
    "X_TRAIN_IMP_TOT = np.concatenate((X_TRAIN_IMP_GBM, X_TRAIN_IMP_LGG))\n",
    "                                \n",
    "#LGG_IMPUTED[:] = ARRAY_IMP_LGG                                                      # Overwrite original values with imputed values in dataframe\n",
    "#LGG_IMPUTED['label'] = 'LGG'                                                        # Add column containing label\n",
    "\n",
    "# Impute test set \n",
    "IMPUTER_TEST.fit(X_TRAIN_IMP_TOT)\n",
    "X_TEST_IMP = IMPUTER_TEST.transform(X_TEST_FEAT_SEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation per feature based on training data\n",
    "MEAN = X_TRAIN_IMP_TOT.mean(axis=0)\n",
    "STD = X_TRAIN_IMP_TOT.std(axis=0)\n",
    "\n",
    "# Evaluate per patient each feature\n",
    "no_outliers = 0\n",
    "for patient in X_TRAIN_IMP_TOT:\n",
    "    feat_out = 0\n",
    "    for feature, mu, std in zip(patient, MEAN, STD):\n",
    "        outlier = ((feature>mu+3*std) | (feature<mu-3*std))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 30:\n",
    "        no_outliers += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling of data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = RobustScaler()\n",
    "SCALER.fit(X_TRAIN_IMP_TOT)\n",
    "X_TRAIN_SCAL = SCALER.transform(X_TRAIN_IMP_TOT)\n",
    "X_TEST_SCAL = SCALER.transform(X_TEST_IMP)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}