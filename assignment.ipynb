{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing functions and packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from missingpy import KNNImputer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting data "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Splitting feature values and patient labels\n",
    "FEATURES = data.drop(columns=['label'])\n",
    "LABELS = data['label']\n",
    "\n",
    "GBM = FEATURES.loc[LABELS=='GBM']\n",
    "LGG = FEATURES.loc[LABELS=='LGG']\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing before crossvalidation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the NaN's in the dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = FEATURES.isnull().sum(axis=1)             # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = FEATURES.isnull().sum(axis=0)             # Number of NaN's per feature for GBM and LGG patients\n",
    "\n",
    "GBM_NO_NAN_COL = GBM.isnull().sum(axis=0)                    # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG.isnull().sum(axis=0)                    # Number of NaN's per feature for LGG patients\n",
    "OVERVIEW_NAN = { 'Total': NO_NAN_COL_TOTAL, 'GBM': GBM_NO_NAN_COL, 'LGG': LGG_NO_NAN_COL } \n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection based on the number of NaN's. Threshold = the maximum number of NaN's in a column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 30\n",
    "PERC_MISSING_LGG = 30\n",
    "\n",
    "# Determining threshold for discarding feature based on above percentage\n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded to list\n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "DATA_FEAT_SEL = FEATURES.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "# The variables (series) below 'bins' the NaN's:\n",
    "# - the index column is the amount of NaN's in the dataset \n",
    "# - the second column is the amount of features that have this amount of NaN's\n",
    "\n",
    "#aantal_NAN_GBM = GBM_no_nan_col.value_counts()\n",
    "#aantal_NAN_LGG = LGG_no_nan_col.value_counts()\n",
    "#aantal_NAN_total = no_nan_col.value_counts()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient selection based on the number of NaN's. Threshold = the maximum number of NaN's in a row."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "These samples are removed from dataset:\nTCGA-HT-7686\n166/167 samples are left in dataset\n"
    }
   ],
   "source": [
    "# Patient selection \n",
    "\n",
    "# Percentage/number of features that a patient is allowed to miss. When above this amount, this patient is removed from the trainingset, because it is missing too many features. \n",
    "PERC_MISSING_SAMPLE = 30\n",
    "\n",
    "# Make the threshold\n",
    "THRESHOLD_SAMPLE = floor((PERC_MISSING_SAMPLE/100) * len(DATA_FEAT_SEL.columns))\n",
    "\n",
    "# Number of NaN's per patient AFTER removing some features\n",
    "NO_NAN_ROW_TRAIN = DATA_FEAT_SEL.isnull().sum(axis=1)      \n",
    "\n",
    "# Make an empty list, which will be filled with samples that are above the threshold\n",
    "SAMPLES_REMOVED = [] \n",
    "LABELS_SEL = LABELS\n",
    "\n",
    "# Looping over the trainingset to determine which patients are above the threshold, and remove them directly.\n",
    "print('These samples are removed from dataset:')\n",
    "for sample in NO_NAN_ROW_TRAIN[NO_NAN_ROW_TRAIN > THRESHOLD_SAMPLE].index[:]:\n",
    "    if sample:\n",
    "        print(sample)\n",
    "        SAMPLES_REMOVED.append(sample)      # This should be removed in combination with the comment before\n",
    "        DATA_FEAT_SEL = DATA_FEAT_SEL.drop(index=sample)\n",
    "        LABELS_SEL = LABELS_SEL.drop(index=sample)\n",
    "\n",
    "print(f'{len(DATA_FEAT_SEL)}/{len(FEATURES)} samples are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of data distribution and outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data distribution: \n",
    "IMPUTER_GBM = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "IMPUTER_LGG = KNNImputer(n_neighbors=5, weights=\"uniform\")        \n",
    "\n",
    "X_GBM = DATA_FEAT_SEL[LABELS_SEL=='GBM']        \n",
    "X_IMP_GBM = IMPUTER_GBM.fit_transform(X_GBM)\n",
    "\n",
    "X_LGG = DATA_FEAT_SEL[LABELS_SEL=='LGG']        \n",
    "X_IMP_LGG = IMPUTER_LGG.fit_transform(X_LGG)   \n",
    "\n",
    "NO_NON_NORMAL_GBM = 0\n",
    "FEAT_NON_NORM_GBM = list()\n",
    "for index, feature in enumerate(X_IMP_GBM.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value<0.05:\n",
    "        NO_NON_NORMAL_GBM += 1 \n",
    "        FEAT_NON_NORM_GBM.append(index)\n",
    "\n",
    "NO_NON_NORMAL_LGG = 0\n",
    "FEAT_NON_NORM_LGG = list()\n",
    "for index, feature in enumerate(X_IMP_LGG.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value<0.05:\n",
    "        NO_NON_NORMAL_LGG += 1 \n",
    "        FEAT_NON_NORM_LGG.append(index)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate per GBM patient each feature\n",
    "NO_OUTLIERS_GBM = 0\n",
    "\n",
    "for patient in X_IMP_GBM:\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):\n",
    "        q25, q75 = np.percentile(X_IMP_GBM[:,index], 25), np.percentile(X_IMP_GBM[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        outlier = ((feature>upper) | (feature<lower))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS_GBM += 1\n",
    "\n",
    "# Evaluate per LGG patient each feature\n",
    "NO_OUTLIERS_LGG = 0\n",
    "\n",
    "for patient in X_IMP_LGG:\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):\n",
    "        q25, q75 = np.percentile(X_IMP_LGG[:,index], 25), np.percentile(X_IMP_LGG[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        outlier = ((feature>upper) | (feature<lower))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS_LGG += 1\n",
    "\n",
    "# Calculate mean and standard deviation per feature based on training data\n",
    "#MEAN = DATA_TOTAL_IMPUTED.mean(axis=0)\n",
    "#STD = DATA_TOTAL_IMPUTED.std(axis=0)\n",
    "\n",
    "# Evaluate per patient each feature\n",
    "#NO_OUTLIERS = 0\n",
    "#for patient in DATA_TOTAL_IMPUTED:\n",
    "#    feat_out = 0\n",
    "#    for feature, mu, std in zip(patient, MEAN, STD):\n",
    "#        outlier = ((feature>mu+3*std) | (feature<mu-3*std))\n",
    "#        feat_out += outlier\n",
    "#    if feat_out > 30:\n",
    "#        no_outliers += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "\n",
    "def knn_impute_train_set(X_train, X_test):\n",
    "    # Definition of imputers\n",
    "    imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    \n",
    "    # Impute train and test set \n",
    "    imputer.fit(X_train)\n",
    "    X_train_imp = imputer.transform(X_train)\n",
    "    X_test_imp = imputer.transform(X_test)\n",
    "    return X_train_imp, X_test_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "def scale_train_and_test_data(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    return X_train_scal, X_test_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using univariate feature selection\n",
    "\n",
    "def select_features_univariate(X_train, y_train, X_test):\n",
    "    selection_method = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "    X_train_sel = selection_method.transform(X_train)\n",
    "    X_test_sel = selection_method.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, selection_method.get_support(indices=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using L1 \n",
    "def select_features_L1(X_train, y_train, X_test):\n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True, threshold = 'median')\n",
    "    X_train_sel = model.transform(X_train)\n",
    "    X_test_sel = model.transform(X_test)\n",
    "    return X_train_sel, X_test_sel, model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using recursive feature elimination\n",
    "\n",
    "def select_features_rfecv(X_train, y_train):\n",
    "\n",
    "    svc = svm.SVC(kernel=\"linear\")\n",
    "    optimal_number_features = list()\n",
    "\n",
    "    # classifications\n",
    "    rfecv = RFECV(\n",
    "        estimator=svc, step=1, \n",
    "        cv=StratifiedKFold(4),\n",
    "        scoring='roc_auc')\n",
    "    rfecv.fit(X_train, y_train)                               \n",
    "\n",
    "    optimal_number_features.append(rfecv.n_features_)\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()\n",
    "\n",
    "    return rfecv.support_\n",
    "    #print(rfecv.ranking_)\n",
    "    #np.absolute(rfecv.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_analysis(X_train, X_test):\n",
    "    pca = PCA(n_components=20)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Random Forrest Classifier\n",
    "\n",
    "def rf_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: Random Forest Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters = {\n",
    "        'n_estimators': [32, 64, 128, 150],\n",
    "        'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'max_depth': [1,6,15,28,32]\n",
    "    }\n",
    "\n",
    "    grid = RandomizedSearchCV(RandomForestClassifier(), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    rf_classifier = grid.best_estimator_\n",
    "    #print(rf_classifier)\n",
    "\n",
    "    return rf_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for K-Nearest Neighbors Classifier\n",
    "\n",
    "def knn_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: K-Nearest Neighbors Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters = {  'n_neighbors': list(range(3,31)),\n",
    "                    'weights': [\"uniform\", \"distance\"]\n",
    "                    }\n",
    "\n",
    "    grid = RandomizedSearchCV(KNeighborsClassifier(), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    knn_classifier = grid.best_estimator_\n",
    "    #print(knn_classifier)\n",
    "\n",
    "    return knn_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search for Support Vector Machine Classifier\n",
    "\n",
    "def svm_randomized_search(X_train, y_train):\n",
    "    '''Perform a Randomized Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: SVM Classifier with optimal hyperparameters'''\n",
    "\n",
    "    parameters =  {'kernel': ['linear', 'rbf', 'poly'],\n",
    "                    'C': [0.01, 0.1, 1, 10, 100], \n",
    "                    'gamma': [1, 0.1, 0.01, 0.001, 'auto', 'scale'],\n",
    "                    'degree': [1, 2, 3, 4, 5],\n",
    "                    'coef0': [0.01, 0.5, 1, 5, 10, 20]} \n",
    "\n",
    "    grid = RandomizedSearchCV(SVC(), parameters, refit=True, verbose=0, n_iter = 20)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    svm_classifier = grid.best_estimator_\n",
    "    #print(svm_classifier)\n",
    "\n",
    "    return svm_classifier\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_classifier(classifier, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    prediction = classifier.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, prediction)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Run 1 of outer crossvalidation\n[  0   1   7   9  10  12  13  16  17 131 161 164 197 200 290 384 387 437\n 439 468]\n{'SVM': 0.7647058823529411, 'RF': 0.8529411764705882, 'KNN': 0.7941176470588235}\nRun 2 of outer crossvalidation\n[  0   1   9  10  12  13  16  17 131 157 161 163 235 237 336 384 437 439\n 468 473]\n{'SVM': 0.8484848484848485, 'RF': 0.8787878787878788, 'KNN': 0.8787878787878788}\nRun 3 of outer crossvalidation\n[  0   1   8   9  10  12  13  16  17 131 161 164 170 235 237 252 339 384\n 387 468]\n{'SVM': 0.9090909090909091, 'RF': 0.9090909090909091, 'KNN': 1.0}\nRun 4 of outer crossvalidation\n[  0   1   8   9  10  12  13  16  17 116 131 157 161 164 237 384 387 388\n 437 468]\n{'SVM': 0.8787878787878788, 'RF': 0.8787878787878788, 'KNN': 0.8787878787878788}\nRun 5 of outer crossvalidation\n[  0   1   8   9  10  12  13  16  17 131 161 170 173 206 209 237 303 384\n 387 468]\n{'SVM': 0.9090909090909091, 'RF': 0.9090909090909091, 'KNN': 0.9090909090909091}\n"
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "ACCURACIES_OUTER = list()\n",
    "FEATURES_SELECTED_TOTAL = list()\n",
    "fold = 0\n",
    "PERFORMANCE = pd.DataFrame(columns=['SVM', 'RF', 'KNN'])\n",
    "\n",
    "for train_index, test_index in skf.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    fold += 1 \n",
    "    print(f'Run {fold} of outer crossvalidation')\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "\n",
    "    gbm_train = X_train[y_train=='GBM']\n",
    "    lgg_train = X_train[y_train=='LGG']\n",
    "\n",
    "    # ---------------------------------- IMPUTATION -----------------------------------\n",
    "\n",
    "    X_train_imp, X_test_imp = knn_impute_train_set(X_train, X_test)\n",
    " \n",
    "    # ------------------------------------ SCALING ----------------------------------------\n",
    "    X_train_scal, X_test_scal = scale_train_and_test_data(X_train_imp, X_test_imp)\n",
    "\n",
    "    # ------------------------------------ FEATURE SELECTION -------------------------------\n",
    "    #RFECV\n",
    "    #selected_features = select_features_rfecv(X_train_scal, y_train)\n",
    "    #X_train_sel = X_train_scal[:,selected_features]\n",
    "    #X_test_sel = X_test_scal[:,selected_features]\n",
    "\n",
    "    # Univariate and L1\n",
    "    X_train_sel, X_test_sel, selected_indices = select_features_univariate(X_train_scal, y_train, X_test_scal)\n",
    "    #X_train_sel, X_test_sel, selected_indices = select_features_L1(X_train_scal, y_train, X_test_scal)\n",
    "    print(selected_indices)\n",
    "    features_selected = list()\n",
    "    for index in selected_indices:\n",
    "        features_selected.append(DATA_FEAT_SEL.columns[index])\n",
    "    FEATURES_SELECTED_TOTAL.append(features_selected)\n",
    "\n",
    "    #X_train_sel, X_test_sel = pca_analysis(X_train_scal, X_test_scal)\n",
    "\n",
    "    # -------------- INNER CROSSVALIDATION HYPERPARAMETERS---------------------------------\n",
    "    svm_classifier = svm_randomized_search(X_train_sel, y_train)   \n",
    "\n",
    "    rf_classifier = rf_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    knn_classifier = knn_randomized_search(X_train_sel, y_train)\n",
    "\n",
    "    clfs = [svm_classifier, rf_classifier, knn_classifier]\n",
    "    clfs_names = ['SVM', 'RF', 'KNN']\n",
    "\n",
    "    # ---------------- OUTER CROSSVALIDATION------------------------------------------------\n",
    "    acc_dict = dict()\n",
    "    accuracy_total = list()\n",
    "\n",
    "    for clf, name in zip(clfs, clfs_names):\n",
    "        acc_dict[name] = get_accuracy_classifier(clf, X_train_sel, y_train, X_test_sel, y_test)\n",
    "    accuracy_total.append(acc_dict)\n",
    "    PERFORMANCE = PERFORMANCE.append(acc_dict, ignore_index=True)\n",
    "    print(acc_dict)\n",
    "    ACCURACIES_OUTER.append(accuracy_total)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SVM        RF       KNN\n0  0.764706  0.852941  0.794118\n1  0.848485  0.878788  0.878788\n2  0.909091  0.909091  1.000000\n3  0.878788  0.878788  0.878788\n4  0.909091  0.909091  0.909091\nSVM    0.862032\nRF     0.885740\nKNN    0.892157\ndtype: float64\n"
    }
   ],
   "source": [
    "print(PERFORMANCE)\n",
    "MEAN_ACC = PERFORMANCE.mean()\n",
    "print(MEAN_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}