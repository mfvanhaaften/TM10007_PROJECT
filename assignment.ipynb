{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The number of samples: 167\nThe number of columns: 725\n"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     Method A: selection based on the number of values that you DO have\n",
    "        --> Threshold = number of required values that you want             \"\"\"\n",
    "\n",
    "# Splitting the data into GBM and LGG\n",
    "\n",
    "GBM = data.loc[data['label'] == 'GBM']\n",
    "LGG = data.loc[data['label'] == 'LGG']\n",
    "\n",
    "# check if a feature has at least {threshold} value per label\n",
    "\n",
    "features_count_removed = []\n",
    "\n",
    "threshold_GBM = 15\n",
    "threshold_LGG = 15\n",
    "\n",
    "for labels, content in GBM.iteritems():\n",
    "    if content.count() < threshold_GBM:\n",
    "        features_count_removed.append(labels)\n",
    "        #print(f'The feature {labels} does not have enough values in the GBM dataset')\n",
    "\n",
    "for labels, content in LGG.iteritems():\n",
    "    if content.count() < threshold_LGG:\n",
    "        features_count_removed.append(labels)\n",
    "        #print(f'The feature {labels} does not have enough values in the LGG dataset')\n",
    "\n",
    "# remove the features that have no data for at least one label\n",
    "\n",
    "data_A_removed = data.drop(columns=[feature for feature in set(features_count_removed)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     Method B: selection based on the number of NaN's\n",
    "        --> Threshold = the maximum number of NaN's in a column    \"\"\"\n",
    "\n",
    "# Determining the number of NaN row-wise and columnwise\n",
    "# Column counting is done on the full data, and for GBM and LGG seperately\n",
    "# It can be usefull to see from which the class the NaN's come from\n",
    "# This should/might be taken into account when selecting the features\n",
    "\n",
    "import pandas as pd\n",
    "no_nan_row = data.isnull().sum(axis=1)\n",
    "no_nan_col = data.isnull().sum(axis=0)\n",
    "GBM_no_nan_col = GBM.isnull().sum(axis=0)\n",
    "LGG_no_nan_col = LGG.isnull().sum(axis=0)\n",
    "\n",
    "frame = { 'Total': no_nan_col, 'GBM': GBM_no_nan_col, 'LGG': LGG_no_nan_col } \n",
    "overview_nan = pd.DataFrame(frame)\n",
    "\n",
    "threshold_GBM = 10\n",
    "threshold_LGG = 10\n",
    "features_NAN_removed = []\n",
    "\n",
    "for features in GBM_no_nan_col[GBM_no_nan_col > threshold_GBM].index[:]:\n",
    "    features_NAN_removed.append(features)\n",
    "\n",
    "for features in LGG_no_nan_col[LGG_no_nan_col > threshold_LGG].index[:]:\n",
    "    features_NAN_removed.append(features)\n",
    "\n",
    "data_B_removed = data.drop(columns=[feature for feature in set(features_NAN_removed)])\n",
    "\n",
    "\n",
    "# The variables (series) below 'bins' the NaN's:\n",
    "# - the index column is the amount of NaN's in the dataset \n",
    "# - the second column is the amount of features that have this amount of NaN's\n",
    "\n",
    "aantal_NAN_GBM = GBM_no_nan_col.value_counts()\n",
    "aantal_NAN_LGG = LGG_no_nan_col.value_counts()\n",
    "aantal_NAN_total = no_nan_col.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, this section is done for the dataset that comes from method B.\n",
    "# To change it to method A: simply change the variable data_B_removed to data_A_removed (4x)\n",
    "\n",
    "# Imputation of the GBM dataset\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "GBM_imputed = data_A_removed.loc[data_A_removed['label'] == 'GBM'].drop(columns=['label'])\n",
    "array_imp_GBM = imputer.fit_transform(GBM_imputed)\n",
    "GBM_imputed[:] = array_imp_GBM\n",
    "GBM_imputed['label'] = 'GBM'\n",
    "\n",
    "\n",
    "# Imputation of the LGG dataset\n",
    "\n",
    "LGG_imputed = data_A_removed.loc[data_A_removed['label'] == 'LGG'].drop(columns=['label'])\n",
    "array_imp_LGG = imputer.fit_transform(LGG_imputed)\n",
    "LGG_imputed[:] = array_imp_LGG\n",
    "LGG_imputed['label'] = 'LGG'\n",
    "\n",
    "# Combining the datasets again\n",
    "\n",
    "data_imputed = GBM_imputed\n",
    "data_imputed = data_imputed.append(LGG_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}