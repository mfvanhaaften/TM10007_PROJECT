{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing functions and packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from missingpy import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting data "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Splitting feature values and patient labels\n",
    "FEATURES = data.drop(columns=['label'])\n",
    "LABELS = data['label']\n",
    "\n",
    "GBM = FEATURES.loc[LABELS=='GBM']\n",
    "LGG = FEATURES.loc[LABELS=='LGG']\n",
    "\n",
    "# Splitting into train and test set --> dit moet weg\n",
    "#X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(FEATURES, LABELS, test_size=0.2, random_state=42)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing before crossvalidation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the NaN's in the dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = FEATURES.isnull().sum(axis=1)             # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = FEATURES.isnull().sum(axis=0)             # Number of NaN's per feature for GBM and LGG patients\n",
    "\n",
    "GBM_NO_NAN_COL = GBM.isnull().sum(axis=0)                    # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG.isnull().sum(axis=0)                    # Number of NaN's per feature for LGG patients\n",
    "OVERVIEW_NAN = { 'Total': NO_NAN_COL_TOTAL, 'GBM': GBM_NO_NAN_COL, 'LGG': LGG_NO_NAN_COL } \n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection based on the number of NaN's. Threshold = the maximum number of NaN's in a column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 30\n",
    "PERC_MISSING_LGG = 30\n",
    "\n",
    "# Determining threshold for discarding feature based on above percentage\n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded to list\n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "DATA_FEAT_SEL = FEATURES.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "# The variables (series) below 'bins' the NaN's:\n",
    "# - the index column is the amount of NaN's in the dataset \n",
    "# - the second column is the amount of features that have this amount of NaN's\n",
    "\n",
    "#aantal_NAN_GBM = GBM_no_nan_col.value_counts()\n",
    "#aantal_NAN_LGG = LGG_no_nan_col.value_counts()\n",
    "#aantal_NAN_total = no_nan_col.value_counts()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient selection based on the number of NaN's. Threshold = the maximum number of NaN's in a row."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient selection \n",
    "\n",
    "# Percentage/number of features that a patient is allowed to miss. When above this amount, this patient is removed from the trainingset, because it is missing too many features. \n",
    "PERC_MISSING_SAMPLE = 30\n",
    "\n",
    "# Make the threshold\n",
    "THRESHOLD_SAMPLE = floor((PERC_MISSING_SAMPLE/100) * len(DATA_FEAT_SEL.columns))\n",
    "\n",
    "# Number of NaN's per patient AFTER removing some features\n",
    "NO_NAN_ROW_TRAIN = DATA_FEAT_SEL.isnull().sum(axis=1)      \n",
    "\n",
    "# Make an empty list, which will be filled with samples that are above the threshold\n",
    "SAMPLES_REMOVED = [] \n",
    "LABELS_SEL = LABELS\n",
    "\n",
    "# Looping over the trainingset to determine which patients are above the threshold, and remove them directly.\n",
    "#print('These samples are removed from dataset:')\n",
    "#for sample in NO_NAN_ROW_TRAIN[NO_NAN_ROW_TRAIN > THRESHOLD_SAMPLE].index[:]:\n",
    "#    if sample:\n",
    "#        print(sample)\n",
    "#        SAMPLES_REMOVED.append(sample)      # This should be removed in combination with the comment before\n",
    "#        DATA_FEAT_SEL = DATA_FEAT_SEL.drop(index=sample)\n",
    "#        LABELS_SEL = LABELS_SEL.drop(index=sample)\n",
    "\n",
    "#print(f'{len(DATA_FEAT_SEL)}/{len(FEATURES)} samples are left in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of data distribution and outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data distribution: \n",
    "IMPUTER_TOTAL = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "DATA_TOTAL_IMPUTED = IMPUTER_TOTAL.fit_transform(DATA_FEAT_SEL)\n",
    "\n",
    "NO_NORM_DISTR = 0\n",
    "FEAT_NORM = list()\n",
    "for index, feature in enumerate(DATA_TOTAL_IMPUTED.T):\n",
    "    t_stat, p_value = shapiro(feature)\n",
    "    if p_value>0.05:\n",
    "        NO_NORM_DISTR += 1 \n",
    "        FEAT_NORM.append(index)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate per patient each feature\n",
    "NO_OUTLIERS = 0\n",
    "\n",
    "for patient in DATA_TOTAL_IMPUTED:\n",
    "    feat_out = 0\n",
    "    for index, feature in enumerate(patient):\n",
    "        q25, q75 = np.percentile(DATA_TOTAL_IMPUTED[:,index], 25), np.percentile(DATA_TOTAL_IMPUTED[:,index], 75)\n",
    "        iqr = q75 - q25\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        outlier = ((feature>upper) | (feature<lower))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 70:\n",
    "        NO_OUTLIERS += 1\n",
    "\n",
    "# Calculate mean and standard deviation per feature based on training data\n",
    "#MEAN = DATA_TOTAL_IMPUTED.mean(axis=0)\n",
    "#STD = DATA_TOTAL_IMPUTED.std(axis=0)\n",
    "\n",
    "# Evaluate per patient each feature\n",
    "#NO_OUTLIERS = 0\n",
    "#for patient in DATA_TOTAL_IMPUTED:\n",
    "#    feat_out = 0\n",
    "#    for feature, mu, std in zip(patient, MEAN, STD):\n",
    "#        outlier = ((feature>mu+3*std) | (feature<mu-3*std))\n",
    "#        feat_out += outlier\n",
    "#    if feat_out > 30:\n",
    "#        no_outliers += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "\n",
    "def knn_impute_train_set(X_train, y_train, X_test):\n",
    "    # Definition of imputers\n",
    "    imputer_gbm = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    imputer_lgg = KNNImputer(n_neighbors=5, weights=\"uniform\")        \n",
    "    imputer_test = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "    # Impute GBM train set\n",
    "    X_train_gbm = X_train[y_train=='GBM']        \n",
    "    X_train_imp_gbm =  imputer_gbm.fit_transform(X_train_gbm)    \n",
    "\n",
    "    # Impute LGG train set\n",
    "    X_train_lgg = X_train[y_train=='LGG']        \n",
    "    X_train_imp_lgg = imputer_lgg.fit_transform(X_train_lgg)    \n",
    "\n",
    "    # Merge imputed GBM and LGG arrays\n",
    "    X_train_imp_tot = np.concatenate((X_train_imp_gbm, X_train_imp_lgg))\n",
    "\n",
    "    # Impute test set \n",
    "    imputer_test.fit(X_train_imp_tot)\n",
    "    X_test_imp = imputer_test.transform(X_test)\n",
    "    \n",
    "    return X_train_imp_tot, X_test_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "def scale_train_and_test_data(X_train, X_test):\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scal = scaler.transform(X_train)\n",
    "    X_test_scal = scaler.transform(X_test)\n",
    "    return X_train_scal, X_test_scal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using recursive feature elimination\n",
    "\n",
    "def select_features_rfecv(X_train, y_train):\n",
    "\n",
    "    svc = svm.SVC(kernel=\"linear\")\n",
    "    optimal_number_features = list()\n",
    "\n",
    "    # classifications\n",
    "    rfecv = RFECV(\n",
    "        estimator=svc, step=1, \n",
    "        cv=StratifiedKFold(4),\n",
    "        scoring='roc_auc')\n",
    "    rfecv.fit(X_train, y_train)                               \n",
    "\n",
    "    optimal_number_features.append(rfecv.n_features_)\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()\n",
    "\n",
    "    return rfecv.support_\n",
    "    #print(rfecv.ranking_)\n",
    "    #np.absolute(rfecv.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_gridsearch(X_TRAIN_SEL, Y_TRAIN):\n",
    "    '''Perform a Grid Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: Random Forest Classifier with optimal hyperparameters'''\n",
    "\n",
    "    model_params = {\n",
    "        'n_estimators': [32, 64, 128, 150],\n",
    "        'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'max_depth': [1,6,15,28,32]\n",
    "    }\n",
    "\n",
    "    GRID = GridSearchCV(RandomForestClassifier(), model_params, refit=True, verbose=1)\n",
    "    GRID.fit(X_TRAIN_SEL, Y_TRAIN)\n",
    "\n",
    "    RandomForest_CLASSIFIER = GRID.best_estimator_\n",
    "    #print(RandomForest_CLASSIFIER)\n",
    "    RESULTS = pd.DataFrame(GRID.cv_results_)\n",
    "\n",
    "    return RandomForest_CLASSIFIER \n",
    "\n",
    "\n",
    "def KNN_gridsearch(X_TRAIN_SEL, Y_TRAIN):\n",
    "    '''Perform a Grid Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: Random Forest Classifier with optimal hyperparameters'''\n",
    "\n",
    "    k_range = list(range(3,31))\n",
    "    weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "    param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "\n",
    "    GRID = GridSearchCV(KNeighborsClassifier(), param_grid, refit=True, verbose=0)\n",
    "    GRID.fit(X_train_sel, y_train)\n",
    "\n",
    "    KNN_CLASSIFIER = GRID.best_estimator_\n",
    "    #print(KNN_CLASSIFIER)\n",
    "    RESULTS = pd.DataFrame(GRID.cv_results_)\n",
    "\n",
    "    return KNN_CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_gridsearch(X_train_sel, Y_train):\n",
    "    '''Perform a Grid Search on the training set \n",
    "    to find the optimal hyperparameters.\n",
    "    Input: training data and labels\n",
    "    Output: SVM Classifier with optimal hyperparameters'''\n",
    "\n",
    "    param_grid =  {'kernel': ['linear', 'rbf', 'poly'],\n",
    "                    'C': [0.01, 0.1, 1, 10, 100]} \n",
    "                    #'gamma': [1, 0.1, 0.01, 0.001, 'auto', 'scale'],\n",
    "                    #'degree': [1, 2, 3, 4, 5],\n",
    "                    #'coef0': [0.01, 0.5, 1, 5, 10, 20]} \n",
    "\n",
    "    GRID = GridSearchCV(SVC(), param_grid, refit=True, verbose=0)\n",
    "    GRID.fit(X_train_sel, y_train)\n",
    "\n",
    "    SVM_CLASSIFIER = GRID.best_estimator_\n",
    "    #print(SVM_CLASSIFIER)\n",
    "    RESULTS = pd.DataFrame(GRID.cv_results_)\n",
    "\n",
    "    return SVM_CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(X_train_sel, y_train, X_test_sel, y_test):\n",
    "\n",
    "    svm_classifier.fit(X_train_sel, y_train)\n",
    "    svm_prediction = svm_classifier.predict(X_test_sel)\n",
    "    svm_accuracy = metrics.accuracy_score(y_test, svm_prediction)\n",
    "\n",
    "    rf_classifier.fit(X_train_sel, y_train)\n",
    "    rf_prediction = rf_classifier.predict(X_test_sel)\n",
    "    rf_accuracy = metrics.accuracy_score(y_test, rf_prediction)\n",
    "\n",
    "    knn_classifier.fit(X_train_sel, y_train)\n",
    "    knn_prediction = knn_classifier.predict(X_test_sel)\n",
    "    knn_accuracy = metrics.accuracy_score(y_test, knn_prediction)\n",
    "\n",
    "    print(f'Accuracy SVM = {svm_accuracy}')\n",
    "    print(f'Accuracy RF = {rf_accuracy}')\n",
    "    print(f'Accuracy KNN = {knn_accuracy}')\n",
    "\n",
    "    return svm_accuracy, rf_accuracy, knn_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-4f1a813157a6>, line 34)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-4f1a813157a6>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    p rint(svm_accuracy)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "# Outer crossvalidation loop\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "column_names = [\"classifier\", \"accuracy\"]\n",
    "df_accuracies = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for train_index, test_index in skf.split(DATA_FEAT_SEL, LABELS_SEL):\n",
    "    X_train, X_test = np.array(DATA_FEAT_SEL)[train_index], np.array(DATA_FEAT_SEL)[test_index]\n",
    "    y_train, y_test = np.array(LABELS_SEL)[train_index], np.array(LABELS_SEL)[test_index]\n",
    "\n",
    "    gbm_train = X_train[y_train=='GBM']\n",
    "    lgg_train = X_train[y_train=='LGG']\n",
    "\n",
    "    # ---------------------------------- IMPUTATION -----------------------------------\n",
    "\n",
    "    X_train_imp, X_test_imp = knn_impute_train_set(X_train, y_train, X_test) \n",
    " \n",
    "    # ------------------------------------ SCALING ----------------------------------------\n",
    "    X_train_scal, X_test_scal = scale_train_and_test_data(X_train_imp, X_test_imp)\n",
    "\n",
    "    # ------------------------------------ FEATURE SELECTION -------------------------------\n",
    "    selected_features = select_features_rfecv(X_train_scal, y_train)\n",
    "    X_train_sel = X_train_scal[:,selected_features]\n",
    "    X_test_sel = X_test_scal[:,selected_features]\n",
    "\n",
    "    # -------------- CLASSIFIERS GRIDSEARCH ---- (uncommand the one you want to try) ----------\n",
    "    svm_hyper = svm_gridsearch(X_train_sel, y_train)   # Support Vector Machine classifier\n",
    "    print(svm_hyper)\n",
    "    svm_hyper.fit(X_train_sel, y_train)\n",
    "    svm_prediction = svm_hyper.predict(X_test_sel)\n",
    "    svm_accuracy = metrics.accuracy_score(y_test, svm_prediction)\n",
    "    p rint(svm_accuracy)\n",
    "\n",
    "    k# nn_classifier = KNN_gridsearch(X_train_sel, y_train)  # K Nearnest Neighbour classifier\n",
    "     # nn_classifier.fit(X_train_sel, y_train)\n",
    "    k# nn_prediction = knn_classifier.predict(X_test_sel)\n",
    "    k# nn_accuracy = metrics.accuracy_score(y_test, knn_prediction)\n",
    "     # rint(knn_accuracy)\n",
    "\n",
    "    rf _classifier = RF_gridsearch(X_train_sel, y_train)   # Random Forrest classifier\n",
    "    rf_classifier .fit(X_train_sel, y_train)\n",
    "    rf_prediction = rf_class ifier.predict(X_test_sel)\n",
    "    rf_accuracy = metrics.accuracy_score (y_test, rf_prediction)\n",
    "    print(rf_accuracy)\n",
    "        # -------- -------TRAINING THE CLASSIFIER WITH HYPERPARAMETERS -& ACCURACIES -----------------------\n",
    "\n",
    "    #df_accuracies = get_accuracies(X_trai n_sel, y_train, X_test_sel, y_test)\n",
    "    svm_accuracy_score = []\n",
    "    rf_accuracy_score = []\n",
    "    knn_accuracy_score = []\n",
    "    svm_accuracy, rf_accuracy, knn_accuracy = get_accuracies(X_train_sel, y_train, X_test_sel, y_test)\n",
    "\n",
    "\n",
    "    svm_accuracy_score.append(svm_accuracy)\n",
    "    rf_accuracy_score.append(rf_accuracy)\n",
    "    knn_accuracy_score.append(knn_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train_sel' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5ee722af0acd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_sel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_sel' is not defined"
     ]
    }
   ],
   "source": [
    "#KNN Classification/ hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = X_train_sel\n",
    "y = y_train\n",
    "\n",
    "k_range = list(range(3,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "#print (param_grid)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy')\n",
    "grid.fit(X,y)\n",
    "\n",
    "#print(grid.grid_scores_)\n",
    "'''\n",
    "print(grid.grid_scores_[0].parameters)\n",
    "print(grid.grid_scores_[0].cv_validation_scores)\n",
    "print(grid.grid_scores_[0].mean_validation_score)\n",
    "'''\n",
    "\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski',metric_params=None, n_jobs=1)\n",
    "knn.fit(X_train_sel, y_train)\n",
    "#predict the response for test dataset\n",
    "y_pred = knn.predict(X_test_sel)\n",
    "from sklearn import metrics \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train_sel' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ec06909e9881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mX_train_sel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_sel' is not defined"
     ]
    }
   ],
   "source": [
    "# Random forest Classification/ hyperparameter tuning\n",
    "\n",
    "model_params = {\n",
    "    'n_estimators': [50, 150, 250],\n",
    "    'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "X= X_train_sel\n",
    "Y= y_train\n",
    "\n",
    "\n",
    "# create random forest classifier model\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# set up grid search meta-estimator\n",
    "clf = GridSearchCV(rf_model, model_params, cv=5)\n",
    "\n",
    "# train the grid search meta-estimator to find the best model\n",
    "model = clf.fit(X, y)\n",
    "\n",
    "# print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "pprint(model.best_estimator_.get_params())\n",
    "\n",
    "predictions = model.predict(X)\n",
    "print(predictions)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_sel,y_train)\n",
    "y_pred=clf.predict(X_test_sel)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}