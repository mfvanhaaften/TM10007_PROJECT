{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 167\nThe number of columns: 725\n"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n",
    "\n",
    "# Splitting the data into GBM and LGG\n",
    "GBM = data.loc[data['label'] == 'GBM']\n",
    "LGG = data.loc[data['label'] == 'LGG']\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Overview of the NaN's in the dataset\"\"\"\n",
    "\n",
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = data.isnull().sum(axis=1)          # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = data.isnull().sum(axis=0)          # Number of NaN's per feature for GBM and LGG patients\n",
    "GBM_NO_NAN_COL = GBM.isnull().sum(axis=0)             # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG.isnull().sum(axis=0)             # Number of NaN's per feature for LGG patients\n",
    "OVERVIEW_NAN = { 'Total': NO_NAN_COL_TOTAL, 'GBM': GBM_NO_NAN_COL, 'LGG': LGG_NO_NAN_COL } \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     Feature selection based on the number of NaN's\n",
    "        Threshold = the maximum number of NaN's in a column    \"\"\"\n",
    "\n",
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 5\n",
    "PERC_MISSING_LGG = 5\n",
    "\n",
    "# Determining threshold for discarding feature based on above percentage\n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded to list\n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "DATA_REMOVED = data.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "\n",
    "# The variables (series) below 'bins' the NaN's:\n",
    "# - the index column is the amount of NaN's in the dataset \n",
    "# - the second column is the amount of features that have this amount of NaN's\n",
    "\n",
    "#aantal_NAN_GBM = GBM_no_nan_col.value_counts()\n",
    "#aantal_NAN_LGG = LGG_no_nan_col.value_counts()\n",
    "#aantal_NAN_total = no_nan_col.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN imputation of missing values\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "# Imputation of the GBM dataset\n",
    "GBM_IMPUTED = DATA_REMOVED.loc[DATA_REMOVED['label'] == 'GBM']                      # Select GBM patients \n",
    "GBM_IMPUTED = GBM_IMPUTED.drop(columns=['label'])                                   # Drop label column for imputation\n",
    "ARRAY_IMP_GBM = imputer.fit_transform(GBM_IMPUTED)                                        \n",
    "GBM_IMPUTED[:] = ARRAY_IMP_GBM                                                      # Overwrite original values with imputed values in dataframe\n",
    "GBM_IMPUTED['label'] = 'GBM'                                                        # Add column containing label\n",
    "\n",
    "# Imputation of the LGG dataset\n",
    "LGG_IMPUTED = DATA_REMOVED.loc[DATA_REMOVED['label'] == 'LGG']                      # Select LGG patients\n",
    "LGG_IMPUTED = LGG_IMPUTED.drop(columns=['label'])                                   # Drop label column for imputation \n",
    "ARRAY_IMP_LGG = imputer.fit_transform(LGG_IMPUTED)                                  \n",
    "LGG_IMPUTED[:] = ARRAY_IMP_LGG                                                      # Overwrite original values with imputed values in dataframe\n",
    "LGG_IMPUTED['label'] = 'LGG'                                                        # Add column containing label\n",
    "\n",
    "# Combine imputed GBM and LGG dataframes into one dataframe\n",
    "DATA_IMPUTED = GBM_IMPUTED\n",
    "DATA_IMPUTED = DATA_IMPUTED.append(LGG_IMPUTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}