{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "outputs": [],
   "source": [
    "# TM10007 Assignment: Prediction of Tumor Grade in Brain Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Kiefer Comassi (4402359), Myrthe van Haaften (4547470), Frédérique Koopman (4470885), Stephanie Stoutjesdijk (4557808)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
    "#!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "#from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from missingpy import KNNImputer\n",
    "\n",
    "from brats.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The number of samples: 167\nThe number of columns: 725\n"
    }
   ],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Splitting feature values and patient labels\n",
    "FEATURES = data.drop(columns=['label'])\n",
    "LABELS = data['label']\n",
    "\n",
    "# Splitting into train and test set\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(FEATURES, LABELS, test_size=0.2, random_state=42)\n",
    "\n",
    "GBM_TRAIN = X_TRAIN.loc[Y_TRAIN=='GBM']\n",
    "LGG_TRAIN = X_TRAIN.loc[Y_TRAIN=='LGG']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the NaN's in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the number of NaN's\n",
    "NO_NAN_ROW_TOTAL = X_TRAIN.isnull().sum(axis=1)             # Number of NaN's per patient for GBM and LGG patients\n",
    "NO_NAN_COL_TOTAL = X_TRAIN.isnull().sum(axis=0)             # Number of NaN's per feature for GBM and LGG patients\n",
    "\n",
    "GBM_NO_NAN_COL = GBM_TRAIN.isnull().sum(axis=0)             # Number of NaN's per feature for GBM patients\n",
    "LGG_NO_NAN_COL = LGG_TRAIN.isnull().sum(axis=0)             # Number of NaN's per feature for LGG patients\n",
    "OVERVIEW_NAN = { 'Total': NO_NAN_COL_TOTAL, 'GBM': GBM_NO_NAN_COL, 'LGG': LGG_NO_NAN_COL } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection based on the number of NaN's. Threshold = the maximum number of NaN's in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define percentage of patients with no data for a certain feature, above which the feature is discarded\n",
    "PERC_MISSING_GBM = 5\n",
    "PERC_MISSING_LGG = 5\n",
    "\n",
    "# Determining threshold for discarding feature based on above percentage\n",
    "THRESHOLD_GBM = floor((PERC_MISSING_GBM/100) * len(GBM_TRAIN.index))\n",
    "THRESHOLD_LGG = floor((PERC_MISSING_LGG/100) * len(LGG_TRAIN.index))\n",
    "\n",
    "# Initialisation\n",
    "FEATURES_REMOVED = []\n",
    "\n",
    "# Append names of features that should be discarded to list\n",
    "\n",
    "for feature in GBM_NO_NAN_COL[GBM_NO_NAN_COL > THRESHOLD_GBM].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "for feature in LGG_NO_NAN_COL[LGG_NO_NAN_COL > THRESHOLD_LGG].index[:]:\n",
    "    FEATURES_REMOVED.append(feature)\n",
    "\n",
    "# Remove features from dataset\n",
    "X_TRAIN_FEAT_SEL = X_TRAIN.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "X_TEST_FEAT_SEL = X_TEST.drop(columns=[features for features in set(FEATURES_REMOVED)])\n",
    "\n",
    "# The variables (series) below 'bins' the NaN's:\n",
    "# - the index column is the amount of NaN's in the dataset \n",
    "# - the second column is the amount of features that have this amount of NaN's\n",
    "\n",
    "#aantal_NAN_GBM = GBM_no_nan_col.value_counts()\n",
    "#aantal_NAN_LGG = LGG_no_nan_col.value_counts()\n",
    "#aantal_NAN_total = no_nan_col.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of imputers\n",
    "IMPUTER_GBM = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "IMPUTER_LGG = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "IMPUTER_TEST = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "# Impute GBM train set\n",
    "X_TRAIN_FEAT_SEL_GBM = X_TRAIN_FEAT_SEL.loc[Y_TRAIN=='GBM']\n",
    "X_TRAIN_IMP_GBM = IMPUTER_GBM.fit_transform(X_TRAIN_FEAT_SEL_GBM)    \n",
    "\n",
    "# Impute LGG train set\n",
    "X_TRAIN_FEAT_SEL_LGG = X_TRAIN_FEAT_SEL.loc[Y_TRAIN=='LGG']\n",
    "X_TRAIN_IMP_LGG = IMPUTER_LGG.fit_transform(X_TRAIN_FEAT_SEL_LGG)    \n",
    "\n",
    "# Merge imputed GBM and LGG arrays\n",
    "X_TRAIN_IMP_TOT = np.concatenate((X_TRAIN_IMP_GBM, X_TRAIN_IMP_LGG))\n",
    "                                \n",
    "#LGG_IMPUTED[:] = ARRAY_IMP_LGG                                                      # Overwrite original values with imputed values in dataframe\n",
    "#LGG_IMPUTED['label'] = 'LGG'                                                        # Add column containing label\n",
    "\n",
    "# Impute test set \n",
    "IMPUTER_TEST.fit(X_TRAIN_IMP_TOT)\n",
    "X_TEST_IMP = IMPUTER_TEST.transform(X_TEST_FEAT_SEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation per feature based on training data\n",
    "MEAN = X_TRAIN_IMP_TOT.mean(axis=0)\n",
    "STD = X_TRAIN_IMP_TOT.std(axis=0)\n",
    "\n",
    "# Evaluate per patient each feature\n",
    "no_outliers = 0\n",
    "for patient in X_TRAIN_IMP_TOT:\n",
    "    feat_out = 0\n",
    "    for feature, mu, std in zip(patient, MEAN, STD):\n",
    "        outlier = ((feature>mu+3*std) | (feature<mu-3*std))\n",
    "        feat_out += outlier\n",
    "    if feat_out > 30:\n",
    "        no_outliers += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = RobustScaler()\n",
    "SCALER.fit(X_TRAIN_IMP_TOT)\n",
    "X_TRAIN_SCAL = SCALER.transform(X_TRAIN_IMP_TOT)\n",
    "X_TEST_SCAL = SCALER.transform(X_TEST_IMP)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}